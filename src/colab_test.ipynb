{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "colab_test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POJfkUeHELGD",
        "colab_type": "code",
        "outputId": "80716861-25a9-4091-a78b-67e21aba7c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWk4rHFeGXuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/proto_data/'\n",
        "PICKLED_DIR = os.path.join(DATA_DIR, 'pickled/')\n",
        "#CONLLU_DIR = os.path.join(DATA_DIR, 'WSJ_conllus/')\n",
        "#MODEL_DIR = '../saved_models/'\n",
        "\n",
        "PROTO_TSV = os.path.join(DATA_DIR, 'protoroles_eng_pb_08302015.tsv')\n",
        "#GLOVE_FILE = {'100': os.path.join(DATA_DIR, 'glove.6B.100d.txt') }\n",
        "\n",
        "SPLITS = ['train', 'dev', 'test'] \n",
        "\n",
        "PROPERTIES = ['instigation', 'volition', 'awareness', 'sentient',\n",
        "'exists_as_physical', 'existed_before', 'existed_during', 'existed_after',\n",
        "'created', 'destroyed', 'predicate_changed_argument', 'change_of_state', \n",
        "'changes_possession', 'change_of_location', 'stationary', 'location_of_event', \n",
        "'makes_physical_contact', 'manipulated_by_another']\n",
        "\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n",
        "\n",
        "weights_path = '/content/drive/My Drive/proto_data/weights.tch'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUBxnzAlVE9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/proto_modules')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wGdMdn8tTO",
        "colab_type": "code",
        "outputId": "296bd042-4125-47c8-ac9f-67d722e56293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW, LBFGS\n",
        "import scipy as sp\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)\n",
        "\n",
        "#import data_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IAS8EuYvxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import unsqueeze\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, \\\n",
        "        pack_padded_sequence, pad_sequence\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self,\n",
        "               n_properties=None,\n",
        "               specific_size=None):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.n_properties = n_properties\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.n_properties * specific_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = x.shape[0]\n",
        "\n",
        "    x = x.view(B, self.n_properties, -1) # (B, n_props, size_specific)\n",
        "\n",
        "    attn_scores = torch.bmm(x, torch.transpose(x, 2, 1)) # (B, n_props, n_props)\n",
        "    dists = F.softmax(attn_scores, -1)\n",
        "    attn_weighted_sum = torch.bmm(dists, x)\n",
        "\n",
        "    x = x + attn_weighted_sum\n",
        "\n",
        "    x = self.layer_norm(x.view(B, -1))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class SPRL(nn.Module):\n",
        "    def __init__(self,\n",
        "            vocab_size=None,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            shared_size=None,\n",
        "            padding_idx=None,\n",
        "            emb_np=None,\n",
        "            properties=None,\n",
        "            use_attention=False,\n",
        "            use_lstm=False,\n",
        "            direction_feature=False,\n",
        "            train_jointly=False,\n",
        "            eye=False,\n",
        "            updates_are_logits=False,\n",
        "            sent_avg=False):\n",
        "        super(SPRL, self).__init__()\n",
        "\n",
        "        self.properties = properties\n",
        "        self.n_properties = len(properties)\n",
        "        self.direction_feature = direction_feature\n",
        "\n",
        "        self.word_emb = nn.Embedding(\n",
        "                vocab_size,\n",
        "                emb_size,\n",
        "                padding_idx=padding_idx)\n",
        "        self.word_emb.weight.data.copy_(torch.Tensor(emb_np))\n",
        "        self.word_emb.weight.requires_grad = False\n",
        "\n",
        "\n",
        "        self.lstm = None\n",
        "        if use_lstm:\n",
        "          self.use_lstm = True\n",
        "          directions = 2\n",
        "          if not train_jointly:\n",
        "            self.lstm = {}\n",
        "            for p in self.properties:\n",
        "              self.lstm[p] = MyLSTM(\n",
        "                emb_size=emb_size,\n",
        "                h_size=h_size,\n",
        "                directions=directions)\n",
        "          else:\n",
        "            self.lstm = MyLSTM(\n",
        "                emb_size=emb_size,\n",
        "                h_size=h_size,\n",
        "                directions=directions)\n",
        "\n",
        "          concatenated_embs_size = 2*(directions*h_size)\n",
        "        \n",
        "        else:\n",
        "          concatenated_embs_size = (2*emb_size) + int(direction_feature)\n",
        "          self.sent_avg = sent_avg\n",
        "          if self.sent_avg:\n",
        "            concatenated_embs_size += emb_size # While testing pred, head, and average sent embedding\n",
        "\n",
        "        self.attention = None\n",
        "        if not use_attention:\n",
        "          shared_size = concatenated_embs_size\n",
        "          #shared_size = self.n_properties\n",
        "          self.shared = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "              nn.ReLU(),\n",
        "              )\n",
        "          self.prop_specific = nn.Sequential(\n",
        "              nn.Linear(shared_size, self.n_properties, bias=True),\n",
        "              )\n",
        "          \n",
        "          #self.clf = nn.Linear(self.n_properties*shared_size, self.n_properties, bias=True)\n",
        "          #self.clf = nn.Linear(shared_size, self.n_properties, bias=True)\n",
        "        else: # \"shared\" not really best name here...\n",
        "          self.attention = True\n",
        "          self.first_guess = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, self.n_properties, bias=True),\n",
        "              #nn.BatchNorm1d(self.n_properties, affine=False)\n",
        "              #nn.ReLU()\n",
        "              )\n",
        "          \n",
        "          self.updates_are_logits = updates_are_logits \n",
        "          \n",
        "          self.updates = nn.Linear(self.n_properties, self.n_properties, bias=True)\n",
        "          # self.updates = nn.Sequential(\n",
        "          #     nn.Linear(self.n_properties, self.n_properties, bias=True),\n",
        "          #     nn.ReLU(),\n",
        "          #     nn.Linear(self.n_properties, self.n_properties, bias=True)\n",
        "          #     )\n",
        "          \n",
        "          self.eye = eye\n",
        "          if self.eye:\n",
        "            self.updates.weight.data -= (torch.eye(self.n_properties) * self.updates.weight.data)\n",
        "\n",
        "\n",
        "    def forward(self, sents, sent_lens, preds, heads, updates=True):\n",
        "\n",
        "        # Sort the sentences so that the LSTM can process properly\n",
        "        B, _, = sents.shape\n",
        "\n",
        "\n",
        "        if self.lstm != None: # i.e., use lstm\n",
        "          lens_sorted = sent_lens\n",
        "          sents_sorted = sents\n",
        "          indices = None\n",
        "          if(len(sents) > 1):\n",
        "              lens_sorted, indices = torch.sort(lens_sorted, descending=True)\n",
        "              lens_sorted = lens_sorted.to(device)\n",
        "              indices = indices.to(device)\n",
        "              sents_sorted = sents_sorted.index_select(0, indices).to(device)\n",
        "          w_embs = self.word_emb(sents_sorted)\n",
        "          packed_lstm_input = pack_padded_sequence(\n",
        "                  w_embs, lens_sorted, batch_first=True)\n",
        "\n",
        "          if type(self.lstm) == type(dict()):\n",
        "            lstm_outs = {p: self.lstm[p](packed_lstm_input, indices) for p in self.properties}\n",
        "            lstm_outs = torch.stack(list(lstm_outs.values()), dim=0).sum(0)\n",
        "          else:\n",
        "            lstm_outs = self.lstm(packed_lstm_input, indices)\n",
        "          pred_reps = lstm_outs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = lstm_outs[np.arange(B), heads] # same as above\n",
        "        else: # no lstm, just MLP\n",
        "          w_embs = self.word_emb(sents)\n",
        "          pred_reps = w_embs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = w_embs[np.arange(B), heads] # same as above\n",
        "          if self.sent_avg:\n",
        "            sent_avg = w_embs.mean(dim=1)\n",
        "\n",
        "        if self.direction_feature:\n",
        "          head_before_pred = torch.unsqueeze((preds > heads), -1).float() # (B,)\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps, head_before_pred], dim=-1) # (B, 2*h_size)\n",
        "          if self.sent_avg:\n",
        "            pred_head_cat = torch.cat([pred_head_cat, sent_avg], dim=-1) # (B, 2*h_size)\n",
        "        else:\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps], dim=-1) # (B, 2*h_size)\n",
        "\n",
        "        x = pred_head_cat\n",
        "        if self.attention == None:\n",
        "          x = pred_head_cat # Experimenting with having no shared and learned rep\n",
        "          x = self.shared(x) # (B, size_shared) # For lstm\n",
        "\n",
        "          logits = self.prop_specific(x)\n",
        "        else:\n",
        "          x = self.first_guess(x)\n",
        "          if updates:\n",
        "            if self.eye:\n",
        "              self.updates.weight.data -= (torch.eye(self.n_properties).to(device) * self.updates.weight.data)\n",
        "            x_up = self.updates(x) # \n",
        "\n",
        "            #logits = x + x_up # Residual model\n",
        "            if self.updates_are_logits:\n",
        "              logits = x_up\n",
        "            else:\n",
        "              logits = x + x_up # Residual model\n",
        "          else:\n",
        "            logits = x\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict(self, logits):\n",
        "        # That is to say, predict 0 if logit < 0 and 1 if logit >= 0\n",
        "        predictions = (logits.sign() + 1) / 2\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "class MyLSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            directions=None):\n",
        "        super(MyLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "                input_size=emb_size,    \n",
        "                hidden_size=h_size,\n",
        "                num_layers=1,\n",
        "                bidirectional=(directions == 2),\n",
        "                batch_first=True,\n",
        "                dropout=0.1,\n",
        "                bias=True)\n",
        "        \n",
        "        self.lstm_drop = nn.Dropout(0.)\n",
        "\n",
        "    def forward(self, packed_lstm_input, indices):\n",
        "        outputs, _ = self.lstm(packed_lstm_input)\n",
        "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "\n",
        "        # Unsort sentences to return to proper alignment with labels\n",
        "        if len(outputs) > 1:\n",
        "            outputs = unsort(outputs, indices)\n",
        "          \n",
        "        outputs = self.lstm_drop(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        " \n",
        "def unsort(batch, indices):\n",
        "    indices_inverted = torch.argsort(indices)\n",
        "    batch = batch.index_select(0, indices_inverted)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahYg0bRx-Xdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(args, model, X, y):\n",
        "    epochs = args['epochs']\n",
        "    batch_size = args['batch_size']\n",
        "    lr = args['lr']\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      if 'updates' in name and 'weight' in name:\n",
        "        original_weights = param.detach().clone()\n",
        "\n",
        "    # Data loaders\n",
        "    loader_train = data_loader(X['train'], y['train'],\n",
        "            batch_size=batch_size, shuffle_idx=True)\n",
        "    loader_dev = data_loader(X['dev'], y['dev'],\n",
        "            batch_size=batch_size, shuffle_idx=False)\n",
        "    n_train_batches = math.ceil(len(X['train']) / batch_size)\n",
        "    n_dev_batches = math.ceil(len(X['dev']) / batch_size)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = Adam(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "    #opt = AdamW(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "    #opt = LBFGS(model.parameters())\n",
        "\n",
        "    # Train loop\n",
        "    training_losses = []\n",
        "    dev_losses = [4]\n",
        "    steps = 0\n",
        "    cma = 0\n",
        "    try:\n",
        "      prev_best = 0.0\n",
        "      for e in range(epochs):\n",
        "        model.train()\n",
        "        steps_ = 0\n",
        "        for b in tqdm(\n",
        "                range(n_train_batches), \n",
        "                ascii=True, \n",
        "                desc=f'Epoch {e+1}/{epochs} progress',\n",
        "                position=0,\n",
        "                leave=True,\n",
        "                ncols=80):\n",
        "          opt.zero_grad()\n",
        "          sents, sent_lens, preds, heads, labels = next(loader_train)\n",
        "\n",
        "          if args['use_attention']:\n",
        "            stop_training_lower = e >= args['stop_training_lower']\n",
        "\n",
        "            #step_updates = e > 0 or steps_ > (n_train_batches / 2)\n",
        "            #if step_updates:\n",
        "            if stop_training_lower:\n",
        "              for p in model.parameters():\n",
        "                p.requires_grad = False\n",
        "              for p in model.updates.parameters():\n",
        "                p.requires_grad = True\n",
        "              \n",
        "              logits = model(sents, sent_lens, preds, heads)\n",
        "              # loss = bce_loss(logits, labels)\n",
        "              # loss.backward()\n",
        "              # opt.step()\n",
        "              # opt.zero_grad()\n",
        "\n",
        "            # Normal step\n",
        "            if not stop_training_lower:\n",
        "              for p in model.parameters():\n",
        "                p.requires_grad = True\n",
        "              for p in model.updates.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "                logits = model(sents, sent_lens, preds, heads, updates=False)\n",
        "              # if b == n_train_batches - 1:\n",
        "              #   print(logits[0])\n",
        "          \n",
        "          else: # Not attention\n",
        "            logits = model(sents, sent_lens, preds, heads)\n",
        "\n",
        "          loss = bce_loss(logits, labels)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "          steps_ += 1\n",
        "          cma = (loss.item() + (steps_-1) * cma) / steps_\n",
        "          training_losses.append(cma)\n",
        "        # end of batch loop\n",
        "        steps += steps_\n",
        "\n",
        "        predictions = get_test_predictions(model, X['dev'], y['dev'])\n",
        "        results, metrics = evaluate(args, predictions, y['dev'])\n",
        "        F, precision, recall = metrics['F'], metrics['precision'], metrics['recall']\n",
        "        #dev_losses.append(np.mean(dev_loss))\n",
        "        dev_losses.append(-1)\n",
        "\n",
        "        print(f\"Epoch {e}, F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "\n",
        "        if F > prev_best:\n",
        "          prev_best = F\n",
        "          torch.save(model.state_dict(), weights_path)\n",
        "\n",
        "        if args['use_attention'] and args['show_weights'] and e >=5:\n",
        "          for name, param in model.named_parameters():\n",
        "            if 'updates' in name and 'weight' in name:\n",
        "              updates_weights = param\n",
        "          with torch.no_grad():\n",
        "            show_weights((updates_weights - original_weights).cpu(), properties=model.properties)\n",
        "            #show_weights((updates_weights).cpu(), properties=model.properties)\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    # End of train loop\n",
        "\n",
        "    model.load_state_dict(torch.load(weights_path))\n",
        "    test_predictions = predictions = get_test_predictions(model, X['dev'], y['dev'])\n",
        "    CI = bootstrap_conf_interval(test_predictions, y['dev'])\n",
        "\n",
        "    print(f'\\n Confidence interval : {CI}\\n')\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=1)\n",
        "\n",
        "    ax[0].plot(np.arange(len(training_losses)), np.array(training_losses), color='orange')\n",
        "    ax[1].plot(np.arange(0, steps+1, n_train_batches), np.array(dev_losses), color='blue')\n",
        "    fig.show()\n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "def show_weights(weights, properties=None, cmap='RdBu'):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    norm = None\n",
        "    if cmap == 'RdBu':\n",
        "      vmax = weights.max()\n",
        "      vmin = weights.min()\n",
        "      if type(weights) == type(torch.randn(1)):\n",
        "        vmax = vmax.item()\n",
        "        vmin = vmin.item()\n",
        "      norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0)\n",
        "\n",
        "    ax.set_xticks(np.arange(len(properties)))\n",
        "    ax.set_yticks(np.arange(len(properties)))\n",
        "    ax.set_xticklabels(properties)\n",
        "    ax.set_yticklabels(properties)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode=\"anchor\")\n",
        "\n",
        "    if norm != None:\n",
        "      plt.imshow(weights, cmap=cmap, norm=norm)\n",
        "    else:\n",
        "      plt.imshow(weights, cmap=cmap)\n",
        "    cbar = plt.colorbar()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def bce_loss(logits, labels):\n",
        "    # Expected labels : (B, num_properties)\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def data_loader(X, y, batch_size=None, shuffle_idx=False):\n",
        "    data = list(zip(X, y))\n",
        "    idx = list(range(len(data)))\n",
        "    while True:\n",
        "        if shuffle_idx:\n",
        "            random.shuffle(idx) # In-place shuffle\n",
        "        \n",
        "        for span in idx_spans(idx, batch_size):\n",
        "            batch = [data[i] for i in span]\n",
        "            yield prepare_batch(batch)\n",
        "\n",
        "\n",
        "def idx_spans(idx, span_size):\n",
        "    for i in range(0, len(idx), span_size):\n",
        "        yield idx[i:i+span_size]\n",
        "\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    # batch[i] = X, y\n",
        "    batch_size = len(batch)\n",
        "    sent_lens = torch.LongTensor([len(x[0][0]) for x in batch])\n",
        "    max_length = torch.max(sent_lens).item()\n",
        "    n_properties = len(batch[0][1])\n",
        "\n",
        "    # Zero is padding index\n",
        "    sents = torch.zeros((batch_size, max_length)).long().to(device)\n",
        "    preds = torch.zeros(batch_size).long().to(device)\n",
        "    heads = torch.zeros(batch_size).long().to(device)\n",
        "    labels = torch.zeros(batch_size, n_properties).to(device)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(batch):\n",
        "        sent, (pred_idx, head_idx) = X_batch\n",
        "        sents[i,:len(sent)] = torch.LongTensor(sent)\n",
        "        preds[i] = pred_idx\n",
        "        heads[i] = head_idx\n",
        "        labels[i] = torch.tensor(y_batch)\n",
        "\n",
        "    return sents, sent_lens, preds, heads, labels\n",
        "\n",
        "\n",
        "            #old dev eval code\n",
        "          # with torch.no_grad():\n",
        "          #   model.eval()\n",
        "          #   tp = 0\n",
        "          #   fp = 0\n",
        "          #   fn = 0\n",
        "          #   dev_loss = 0\n",
        "          #   for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80, position=0, leave=True):\n",
        "          #     sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "          #     results_, metrics_, dev_loss_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "          #     tp += results_['tp']\n",
        "          #     fp += results_['fp']\n",
        "          #     fn += results_['fn']\n",
        "          #     dev_loss += dev_loss_.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyxihDMkczmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def evaluate(args, model, sents, sent_lens, preds, heads, labels):\n",
        "#     # Get predictions\n",
        "#     logits = model(sents, sent_lens, preds, heads)\n",
        "#     dev_loss = bce_loss(logits, labels)\n",
        "#     predictions = model.predict(logits)\n",
        "\n",
        "#     predictions, labels = predictions.cpu().numpy(), labels.cpu().numpy()\n",
        "#     results, metrics = get_results_metrics(predictions, labels)\n",
        "\n",
        "#     return results, metrics, dev_loss\n",
        "\n",
        "\n",
        "def evaluate(args, predictions, labels):\n",
        "    # Get predictions\n",
        "    labels = np.array(labels)\n",
        "    predictions, labels = predictions.cpu().numpy(), labels\n",
        "    results, metrics = get_results_metrics(predictions, labels)\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "\n",
        "def get_results_metrics(predictions, labels):\n",
        "    n_correct = (predictions == labels).astype(int).sum()\n",
        "\n",
        "    # Precision, Recall\n",
        "    eq = predictions == labels\n",
        "    neq = predictions != labels\n",
        "\n",
        "    pos_preds = predictions == 1\n",
        "    neg_preds = predictions == 0\n",
        "\n",
        "    tp = np.where(pos_preds, eq, 0).astype(int).sum()\n",
        "    fp = np.where(pos_preds, neq, 0).astype(int).sum()\n",
        "    fn = np.where(neg_preds, neq, 0).astype(int).sum()\n",
        "    \n",
        "    results = {\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'fn': fn\n",
        "            }\n",
        "\n",
        "    F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "    metrics = {'F': F, 'precision': precision, 'recall': recall}\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "\n",
        "def F_precision_recall(tp, fp, fn):\n",
        "    if tp + fp > 0.:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0.\n",
        "\n",
        "    if tp + fn > 0.:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0.\n",
        "\n",
        "    if precision + recall > 0.:\n",
        "        F = (2 * precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        F = 0.\n",
        "\n",
        "    return F, precision, recall\n",
        "\n",
        "\n",
        "def micro_average(results):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    for v in results.values():\n",
        "        tp += v['tp']\n",
        "        fp += v['fp']\n",
        "        fn += v['fn']\n",
        "    \n",
        "    return F_precision_recall(tp, fp, fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuRNj885-f2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5YvM4uHvsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(args):\n",
        "    df = pd.read_csv(PROTO_TSV, sep='\\t')\n",
        "\n",
        "    # Sentences\n",
        "    sent_ids = set(df['Sentence.ID'].tolist())\n",
        "    sents_path = os.path.join(PICKLED_DIR, 'sents.pkl')\n",
        "    sents = None\n",
        "    with open(sents_path, 'rb') as f:\n",
        "      sents = pickle.load(f)\n",
        "\n",
        "    # Dependency data\n",
        "    # dependencies_path = os.path.join(PICKLED_DIR, 'dependencies.pkl')\n",
        "    # with open(dependencies_path, 'rb') as f:\n",
        "    #     deps, deps_just_tokens = pickle.load(f)  \n",
        "    # sents['dependencies'] = deps\n",
        "    # sents['deps_just_tokens'] = deps_just_tokens\n",
        "\n",
        "\n",
        "    # Instances\n",
        "    path = os.path.join(PICKLED_DIR, 'instances.pkl')\n",
        "    proto_instances = None\n",
        "    possible = None # Data to compare to SPRL paper\n",
        "    with open(path, 'rb') as f:\n",
        "      proto_instances, possible = pickle.load(f)\n",
        "\n",
        "    # Word embedding data\n",
        "    w2e = None\n",
        "    path = os.path.join(PICKLED_DIR, f\"glove_{args['glove_d']}.pkl\")\n",
        "    with open(path, 'rb') as f:\n",
        "      w2e = pickle.load(f)\n",
        "\n",
        "    w2i, i2w = None, None\n",
        "    emb_np = None\n",
        "    X, y = None, None\n",
        "    dicts_path = os.path.join(PICKLED_DIR, 'dicts.pkl')\n",
        "    with open(dicts_path, 'rb') as f:\n",
        "        w2i, i2w = pickle.load(f)\n",
        "    \n",
        "    emb_np_path = os.path.join(PICKLED_DIR, 'emb_np.pkl')\n",
        "    with open(emb_np_path, 'rb') as f:\n",
        "        emb_np = pickle.load(f)\n",
        "    \n",
        "    lstm_data_path = os.path.join(PICKLED_DIR, 'lstm_data.pkl')\n",
        "    with open(lstm_data_path, 'rb') as f:\n",
        "        X, y = pickle.load(f)\n",
        "\n",
        "    return {'df': df, \n",
        "            'proto_instances': proto_instances, \n",
        "            'possible': possible,\n",
        "            'sents': sents,\n",
        "            'w2e': w2e,\n",
        "            'sent_ids': sent_ids,\n",
        "            'lstm_data': (X,y),\n",
        "            'dicts': (w2i, i2w),\n",
        "            'emb_np': emb_np}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erm6Foa6jWJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def co_occurrences(y_train, normalize=False):\n",
        "  n_props = y_train[0].shape[0]\n",
        "\n",
        "  co_occur = np.zeros((n_props, n_props))\n",
        "  anti_occur = np.zeros((n_props, n_props))\n",
        "  both_negative = np.zeros((n_props, n_props))\n",
        "  row_pos_col_neg = np.zeros((n_props, n_props))\n",
        "  row_neg_col_pos = np.zeros((n_props, n_props))\n",
        "\n",
        "  positive_counts = np.zeros(n_props)\n",
        "  for labels in y_train:\n",
        "    for i in range(n_props):\n",
        "      if labels[i] == 1:\n",
        "        positive_counts[i] += 1\n",
        "        for j in range(i+1, n_props):\n",
        "          if labels[j] == 1:\n",
        "            co_occur[i,j] += 1\n",
        "\n",
        "        for j in range(n_props):\n",
        "          if labels[j] == 0:\n",
        "            row_pos_col_neg[i,j] += 1\n",
        "        \n",
        "      else: # labels[i] == 0\n",
        "        for j in range(i+1, n_props):\n",
        "          if labels[j] == 0:\n",
        "            both_negative[i,j] += 1\n",
        "        \n",
        "        for j in range(n_props):\n",
        "          if labels[j] == 1:\n",
        "            row_neg_col_pos[i,j] += 1\n",
        "  \n",
        "  negative_counts = len(y_train) - positive_counts\n",
        "\n",
        "  # Mirror over diagonal\n",
        "  co_occur = co_occur + np.transpose(co_occur)\n",
        "  both_negative = both_negative + np.transpose(both_negative)\n",
        "  #anti_occur = anti_occur + np.transpose(anti_occur)\n",
        "\n",
        "  def normalize_rows(array):\n",
        "    array /= np.sum(array, axis=-1, keepdims=True)\n",
        "\n",
        "  positive_counts = np.expand_dims(positive_counts, axis=-1)\n",
        "\n",
        "  # all_ = co_occur + both_negative + row_neg_col_pos + row_pos_col_neg\n",
        "  # print(all_)\n",
        "  # breakpoint()\n",
        "\n",
        "  if normalize:\n",
        "    #co_occur /= positive_counts\n",
        "    normalize_rows(co_occur)\n",
        "    #row_pos_col_neg /= positive_counts\n",
        "    normalize_rows(row_neg_col_pos)\n",
        "\n",
        "\n",
        "\n",
        "  #print(f'Now max of anti_occur is {np.max(anti_occur)}, compared to {np.max(negative_counts)}')\n",
        "  \n",
        "\n",
        "  return co_occur, both_negative, row_pos_col_neg, row_neg_col_pos\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNVWhg68C0iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MidpointNormalize(mpl.colors.Normalize):\n",
        "    def __init__(self, vmin, vmax, midpoint=0, clip=False):\n",
        "        self.midpoint = midpoint\n",
        "        mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
        "\n",
        "    def __call__(self, value, clip=None):\n",
        "        normalized_min = max(0, 1 / 2 * (1 - abs((self.midpoint - self.vmin) / (self.midpoint - self.vmax))))\n",
        "        normalized_max = min(1, 1 / 2 * (1 + abs((self.vmax - self.midpoint) / (self.midpoint - self.vmin))))\n",
        "        normalized_mid = 0.5\n",
        "        x, y = [self.vmin, self.midpoint, self.vmax], [normalized_min, normalized_mid, normalized_max]\n",
        "        return sp.ma.masked_array(sp.interp(value, x, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1On2T0rcKKwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bootstrap_conf_interval(predictions, labels, B=10000):\n",
        "  predictions = predictions.cpu().numpy() # (n_test,18)\n",
        "  N = predictions.shape[0]\n",
        "  indices = np.arange(N)\n",
        "  \n",
        "  labels = np.array(labels)\n",
        "\n",
        "  bs_samples = []\n",
        "  for b in tqdm(range(B), desc='Getting bootstrap samples', ncols=80, position=0, leave=True):\n",
        "    idx = np.random.choice(indices, N)\n",
        "    curr_preds = predictions[idx]\n",
        "    curr_labels = labels[idx]\n",
        "    results, metrics = get_results_metrics(curr_preds, curr_labels)\n",
        "    micro_f1 = metrics['F']\n",
        "    bs_samples.append(micro_f1)\n",
        "\n",
        "  plt.hist(bs_samples)\n",
        "  \n",
        "  return np.quantile(bs_samples, [0.025, 0.975])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7fJuKWbmsJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_predictions(model, X_test, y_test, batch_size=100):\n",
        "\n",
        "  loader_test = data_loader(X_test, y_test, batch_size=batch_size, shuffle_idx=False)\n",
        "\n",
        "  n_batches = math.ceil(len(X_test) / batch_size)\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for b in tqdm(range(n_batches), ascii=True, desc=f'Getting test predictions', ncols=80, position=0, leave=True):\n",
        "      sents, sent_lens, preds, heads, _ = next(loader_test)\n",
        "      logits = model(sents, sent_lens, preds, heads)\n",
        "      predictions.append(model.predict(logits))\n",
        "  \n",
        "  predictions = torch.cat(predictions, dim=0)\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUbR-mhy-dRb",
        "colab_type": "code",
        "outputId": "ebcafa95-579b-4d34-a816-a9ddb9ded2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args = {\n",
        "    'epochs': 10,\n",
        "    'seed': 7,\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 100,\n",
        "    'h_size': 100,\n",
        "    #'shared_size': 300,\n",
        "    'glove_d': 300,\n",
        "    'use_attention': False,\n",
        "    'use_lstm': False,\n",
        "    'train_jointly': True, # Train the lstm jointly\n",
        "\n",
        "    'show_weights': False,\n",
        "\n",
        "    'stop_training_lower': 5,\n",
        "    'eye':True,\n",
        "    'updates_are_logits':False,\n",
        "\n",
        "    'sent_avg':True\n",
        "}\n",
        "\n",
        "seed = args['seed']\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "data = get_data(args)\n",
        "\n",
        "w2i, i2w = data['dicts']\n",
        "emb_np = data['emb_np']\n",
        "X, y = data['lstm_data']\n",
        "\n",
        "# co_occur, both_negative, row_pos_col_neg, row_neg_col_pos = co_occurrences(y['train'], normalize=False)\n",
        "# show_weights(co_occur + both_negative, properties=PROPERTIES, cmap='Greens')\n",
        "# show_weights(row_pos_col_neg + row_neg_col_pos, properties=PROPERTIES, cmap='Reds')\n",
        "# show_weights((co_occur + both_negative) - (row_pos_col_neg + row_neg_col_pos), properties=PROPERTIES)\n",
        "#breakpoint()\n",
        "\n",
        "model = SPRL(\n",
        "    vocab_size=len(w2i),\n",
        "    emb_size=int(args['glove_d']),\n",
        "    h_size=args['h_size'],\n",
        "    #shared_size=args['shared_size'],\n",
        "    padding_idx=w2i[PAD_TOKEN],\n",
        "    emb_np=emb_np,\n",
        "    properties=PROPERTIES,\n",
        "    use_attention=args['use_attention'],\n",
        "    use_lstm=args['use_lstm'],\n",
        "    direction_feature=not args['use_lstm'],\n",
        "    train_jointly=args['train_jointly'],\n",
        "    eye=args['eye'],\n",
        "    updates_are_logits=args['updates_are_logits'],\n",
        "    sent_avg=args['sent_avg'])\n",
        "model.to(device)\n",
        "\n",
        "train(args, model, X, y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 progress: 100%|######################| 78/78 [00:00<00:00, 79.69it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 84.23it/s]\n",
            "Epoch 2/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 77.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, F=75.38, p=80.27, r=71.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10 progress: 100%|######################| 78/78 [00:00<00:00, 78.06it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 95.44it/s]\n",
            "Epoch 3/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 75.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, F=77.98, p=81.23, r=74.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10 progress: 100%|######################| 78/78 [00:00<00:00, 78.22it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 88.28it/s]\n",
            "Epoch 4/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 76.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, F=79.01, p=82.39, r=75.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10 progress: 100%|######################| 78/78 [00:01<00:00, 76.37it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 83.90it/s]\n",
            "Epoch 5/10 progress:   8%|#7                     | 6/78 [00:00<00:01, 59.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, F=79.56, p=81.46, r=77.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10 progress: 100%|######################| 78/78 [00:01<00:00, 75.86it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 88.86it/s]\n",
            "Epoch 6/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 78.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, F=78.84, p=83.83, r=74.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10 progress: 100%|######################| 78/78 [00:00<00:00, 79.82it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 87.66it/s]\n",
            "Epoch 7/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 77.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, F=80.20, p=82.10, r=78.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/10 progress: 100%|######################| 78/78 [00:01<00:00, 74.83it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 64.64it/s]\n",
            "Epoch 8/10 progress:   8%|#7                     | 6/78 [00:00<00:01, 53.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, F=79.75, p=80.47, r=79.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10 progress: 100%|######################| 78/78 [00:01<00:00, 71.80it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 69.50it/s]\n",
            "Epoch 9/10 progress:   9%|##                     | 7/78 [00:00<00:01, 61.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, F=79.95, p=81.67, r=78.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10 progress: 100%|######################| 78/78 [00:01<00:00, 73.66it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 95.96it/s]\n",
            "Epoch 10/10 progress:  10%|##2                   | 8/78 [00:00<00:00, 73.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, F=80.13, p=81.78, r=78.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10 progress: 100%|#####################| 78/78 [00:01<00:00, 67.39it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 68.89it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 88.13it/s]\n",
            "Getting bootstrap samples:   0%|                      | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, F=79.83, p=80.13, r=79.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting bootstrap samples: 100%|████████| 10000/10000 [00:05<00:00, 1977.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Confidence interval : [0.78912448 0.81472695]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAR0ElEQVR4nO3df6zd9X3f8eerNoE2/QEJLiK2F3utp9RMrZN5hK6dmgYFDEgz0bbUSEusCMnpBFsr9R/TTiJKh0SmNUhRUzRXWCFVGwuljWIFb8SjSFGykGASB7AZ4YY4xR6B25KkJVHpjN7743ycnZD749x7zz2Hy+f5kI7O97y/n+/3+3nL+HW//n6/95CqQpLUhx+b9gQkSZNj6EtSRwx9SeqIoS9JHTH0Jakj66c9gYVcfPHFtWXLlmlPQ5LWlIcffvivq2rDXOte0aG/ZcsWjh07Nu1pSNKakuSb863z8o4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk0d/ITXIB8Fng/Db+E1V1a5KtwCHg9cDDwLur6h+SnA98DPhnwN8Av1FVp9q+bgFuBF4C/mNV3Tf+lqTJ2LL/3qkc99Tt103luHp1GOVM/0Xg7VX1S8AOYFeSK4APAndU1c8D32YQ5rT3b7f6HW0cSbYDe4DLgF3AHyVZN85mJEkLWzT0a+CF9vG89irg7cAnWv1u4Pq2vLt9pq2/Mkla/VBVvVhV3wBmgMvH0oUkaSQjXdNPsi7JceA54CjwdeA7VXW2DTkNbGzLG4GnAdr67zK4BPSD+hzbDB9rX5JjSY7Nzs4uvSNJ0rxGCv2qeqmqdgCbGJydv2m1JlRVB6pqZ1Xt3LBhzm8GlSQt05Ke3qmq7wAPAL8MXJjk3I3gTcCZtnwG2AzQ1v8Mgxu6P6jPsY0kaQJGeXpnA/B/q+o7SX4ceAeDm7MPAP+GwRM8e4FPtU0Ot89faOv/sqoqyWHgz5J8CHgDsA340pj7UWem9QSNtFaN8j9RuRS4uz1p82PAPVX16SQngUNJ/jPwFeCuNv4u4E+SzADPM3hih6o6keQe4CRwFripql4abzuSpIUsGvpV9Qjw5jnqTzHH0zdV9ffAv51nX7cBty19mpKkcfA3ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4uGfpLNSR5IcjLJiSS/1ervT3ImyfH2unZom1uSzCR5IsnVQ/VdrTaTZP/qtCRJms/6EcacBX6nqr6c5KeAh5McbevuqKr/Ojw4yXZgD3AZ8Abgfyb5J231R4B3AKeBh5IcrqqT42hEkrS4RUO/qp4BnmnLf5fkcWDjApvsBg5V1YvAN5LMAJe3dTNV9RRAkkNtrKEvSROypGv6SbYAbwa+2Eo3J3kkycEkF7XaRuDpoc1Ot9p89ZcfY1+SY0mOzc7OLmV6kqRFjBz6SX4S+HPgt6vqb4E7gZ8DdjD4l8AfjGNCVXWgqnZW1c4NGzaMY5eSpGaUa/okOY9B4P9pVf0FQFU9O7T+j4FPt49ngM1Dm29qNRaoS5ImYJSndwLcBTxeVR8aql86NOydwGNt+TCwJ8n5SbYC24AvAQ8B25JsTfIaBjd7D4+nDUnSKEY50/8V4N3Ao0mOt9rvAjck2QEUcAp4H0BVnUhyD4MbtGeBm6rqJYAkNwP3AeuAg1V1Yoy9SJIWMcrTO58DMseqIwtscxtw2xz1IwttJ0laXf5GriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZNHQT7I5yQNJTiY5keS3Wv11SY4mebK9X9TqSfLhJDNJHknylqF97W3jn0yyd/XakiTNZZQz/bPA71TVduAK4KYk24H9wP1VtQ24v30GuAbY1l77gDth8EMCuBV4K3A5cOu5HxSSpMlYNPSr6pmq+nJb/jvgcWAjsBu4uw27G7i+Le8GPlYDDwIXJrkUuBo4WlXPV9W3gaPArrF2I0la0JKu6SfZArwZ+CJwSVU901Z9C7ikLW8Enh7a7HSrzVd/+TH2JTmW5Njs7OxSpidJWsTIoZ/kJ4E/B367qv52eF1VFVDjmFBVHaiqnVW1c8OGDePYpSSpGSn0k5zHIPD/tKr+opWfbZdtaO/PtfoZYPPQ5ptabb66JGlCRnl6J8BdwONV9aGhVYeBc0/g7AU+NVR/T3uK5wrgu+0y0H3AVUkuajdwr2o1SdKErB9hzK8A7wYeTXK81X4XuB24J8mNwDeBd7V1R4BrgRng+8B7Aarq+SS/DzzUxn2gqp4fSxeSpJEsGvpV9Tkg86y+co7xBdw0z74OAgeXMkFJ0vj4G7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWT9tCcgaWm27L93asc+dft1Uzu2xsMzfUnqyKKhn+RgkueSPDZUe3+SM0mOt9e1Q+tuSTKT5IkkVw/Vd7XaTJL9429FkrSYUc70PwrsmqN+R1XtaK8jAEm2A3uAy9o2f5RkXZJ1wEeAa4DtwA1trCRpgha9pl9Vn02yZcT97QYOVdWLwDeSzACXt3UzVfUUQJJDbezJJc9YkrRsK7mmf3OSR9rln4tabSPw9NCY0602X/1HJNmX5FiSY7OzsyuYniTp5ZYb+ncCPwfsAJ4B/mBcE6qqA1W1s6p2btiwYVy7lSSxzEc2q+rZc8tJ/hj4dPt4Btg8NHRTq7FAXa8C03yMUNLolnWmn+TSoY/vBM492XMY2JPk/CRbgW3Al4CHgG1JtiZ5DYObvYeXP21J0nIseqaf5OPA24CLk5wGbgXelmQHUMAp4H0AVXUiyT0MbtCeBW6qqpfafm4G7gPWAQer6sTYu5EkLWiUp3dumKN81wLjbwNum6N+BDiypNlJksbK38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4sGvpJDiZ5LsljQ7XXJTma5Mn2flGrJ8mHk8wkeSTJW4a22dvGP5lk7+q0I0layChn+h8Fdr2sth+4v6q2Afe3zwDXANvaax9wJwx+SAC3Am8FLgduPfeDQpI0OYuGflV9Fnj+ZeXdwN1t+W7g+qH6x2rgQeDCJJcCVwNHq+r5qvo2cJQf/UEiSVply72mf0lVPdOWvwVc0pY3Ak8PjTvdavPVf0SSfUmOJTk2Ozu7zOlJkuay4hu5VVVAjWEu5/Z3oKp2VtXODRs2jGu3kiSWH/rPtss2tPfnWv0MsHlo3KZWm68uSZqg5Yb+YeDcEzh7gU8N1d/TnuK5Avhuuwx0H3BVkovaDdyrWk2SNEHrFxuQ5OPA24CLk5xm8BTO7cA9SW4Evgm8qw0/AlwLzADfB94LUFXPJ/l94KE27gNV9fKbw5KkVbZo6FfVDfOsunKOsQXcNM9+DgIHlzQ7SdJY+Ru5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRFYV+klNJHk1yPMmxVntdkqNJnmzvF7V6knw4yUySR5K8ZRwNSJJGN44z/V+vqh1VtbN93g/cX1XbgPvbZ4BrgG3ttQ+4cwzHliQtwWpc3tkN3N2W7wauH6p/rAYeBC5McukqHF+SNI+Vhn4Bn0nycJJ9rXZJVT3Tlr8FXNKWNwJPD217utV+SJJ9SY4lOTY7O7vC6UmShq1f4fa/WlVnkvwscDTJ/x5eWVWVpJayw6o6ABwA2Llz55K2lSQtbEVn+lV1pr0/B3wSuBx49txlm/b+XBt+Btg8tPmmVpMkTciyQz/Ja5P81Lll4CrgMeAwsLcN2wt8qi0fBt7TnuK5Avju0GUgSdIErOTyziXAJ5Oc28+fVdX/SPIQcE+SG4FvAu9q448A1wIzwPeB967g2JKkZVh26FfVU8AvzVH/G+DKOeoF3LTc40mSVm6lN3IldWTL/nunctxTt183leO+Ghn6rzLT+kspaW3wu3ckqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJ+2hN4Ndqy/95pT0GS5mToS3rFm+aJ1Knbr5vasVfDxC/vJNmV5IkkM0n2T/r4ktSziYZ+knXAR4BrgO3ADUm2T3IOktSzSV/euRyYqaqnAJIcAnYDJ1fjYF5bl7RS08qR1bqsNOnQ3wg8PfT5NPDW4QFJ9gH72scXkjwxobmNw8XAX097EqvI/tY2+1tD8sEfKS2lvzfOt+IVdyO3qg4AB6Y9j+VIcqyqdk57HqvF/tY2+1vbxtXfpG/kngE2D33e1GqSpAmYdOg/BGxLsjXJa4A9wOEJz0GSujXRyztVdTbJzcB9wDrgYFWdmOQcVtmavCy1BPa3ttnf2jaW/lJV49iPJGkN8Lt3JKkjhr4kdcTQH9FiXx+R5I4kx9vra0m+M7TuvyQ5keTxJB9OksnOfnEr7O+DSR5rr9+Y7MxHM0J//yjJA0m+kuSRJNcOrbulbfdEkqsnO/PRLLe/JK9v9ReS/OHkZz6aFfT3jiQPJ3m0vb998rNf2Ap6u3zo7+RXk7xzpANWla9FXgxuOn8d+MfAa4CvAtsXGP8fGNykBvgXwOfbPtYBXwDeNu2extjfdcBRBg8FvJbBE1o/Pe2eltofg5tk/74tbwdODS1/FTgf2Nr2s27aPY2xv9cCvwr8JvCH0+5lFfp7M/CGtvxPgTPT7meMvf0EsL4tXwo8d+7zQi/P9Efzg6+PqKp/AM59fcR8bgA+3pYLuIDBH+j5wHnAs6s41+VYSX/bgc9W1dmq+h7wCLBrVWe7dKP0V8BPt+WfAf5PW94NHKqqF6vqG8BM298rybL7q6rvVdXngL+f1GSXYSX9faWqzv1ZngB+PMn5E5jzqFbS2/er6myrX9DGLcrQH81cXx+xca6BSd7I4IzwLwGq6gvAA8Az7XVfVT2+qrNdumX3x+DMZFeSn0hyMfDr/PAv4L0SjNLf+4F/l+Q0cITBv2ZG3XbaVtLfWjCu/v418OWqenE1JrlMK+otyVuTnAAeBX5z6IfAvAz98dsDfKKqXgJI8vPALzD47eONwNuT/Mspzm+lfqi/qvoMg/8Q/xeDs/8vAC9Nb3rLdgPw0araBFwL/EmSV9Pfj677S3IZ8EHgfVOa30rM21tVfbGqLgP+OXBLkgsW29mr6Q99NS3l6yP28P8vfQC8E3iwql6oqheA/w788qrMcvlW0h9VdVtV7aiqdwABvrYqs1y+Ufq7EbgHfvCvswsYfMHVWvjqkJX0txasqL8km4BPAu+pqq+v+myXZix/du3qwQsM7lssyNAfzUhfH5HkTcBFDM52z/kr4NeSrE9yHvBrwCvt8s6y+0uyLsnr2/IvAr8IfGYisx7dKP39FXAlQJJfYPAXa7aN25Pk/CRbgW3AlyY289GspL+1YNn9JbkQuBfYX1Wfn+CcR7WS3rYmWd/qbwTeBJxa9IjTvnu9Vl4M/ln1NQZ32n+v1T4A/KuhMe8Hbn/ZduuA/8Yg6E8CH5p2L2Pu74LW10ngQWDHtHtZTn8Mbkh/nsE9iuPAVUPb/l7b7gngmmn3sgr9nQKeZ3CmeJoFntxaa/0B/wn4Xqude/3stPsZU2/vZnBz+jjwZeD6UY7n1zBIUke8vCNJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkf+H6mfMp7AVZ/9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}