{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "colab_test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POJfkUeHELGD",
        "colab_type": "code",
        "outputId": "0b9b854b-11b5-4140-ec6e-28ec30da2da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWk4rHFeGXuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/proto_data/'\n",
        "PICKLED_DIR = os.path.join(DATA_DIR, 'pickled/')\n",
        "#CONLLU_DIR = os.path.join(DATA_DIR, 'WSJ_conllus/')\n",
        "#MODEL_DIR = '../saved_models/'\n",
        "\n",
        "PROTO_TSV = os.path.join(DATA_DIR, 'protoroles_eng_pb_08302015.tsv')\n",
        "#GLOVE_FILE = {'100': os.path.join(DATA_DIR, 'glove.6B.100d.txt') }\n",
        "\n",
        "SPLITS = ['train', 'dev', 'test'] \n",
        "\n",
        "PROPERTIES = ['instigation', 'volition', 'awareness', 'sentient',\n",
        "'exists_as_physical', 'existed_before', 'existed_during', 'existed_after',\n",
        "'created', 'destroyed', 'predicate_changed_argument', 'change_of_state', \n",
        "'changes_possession', 'change_of_location', 'stationary', 'location_of_event', \n",
        "'makes_physical_contact', 'manipulated_by_another']\n",
        "\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n",
        "\n",
        "weights_path = '/content/drive/My Drive/proto_data/weights.tch'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUBxnzAlVE9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/proto_modules')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wGdMdn8tTO",
        "colab_type": "code",
        "outputId": "29791492-4b8f-4c7a-e416-eb236c609997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW, LBFGS\n",
        "import scipy as sp\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)\n",
        "\n",
        "#import data_utils"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IAS8EuYvxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import unsqueeze\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, \\\n",
        "        pack_padded_sequence, pad_sequence\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self,\n",
        "               n_properties=None,\n",
        "               specific_size=None):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.n_properties = n_properties\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.n_properties * specific_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = x.shape[0]\n",
        "\n",
        "    x = x.view(B, self.n_properties, -1) # (B, n_props, size_specific)\n",
        "\n",
        "    attn_scores = torch.bmm(x, torch.transpose(x, 2, 1)) # (B, n_props, n_props)\n",
        "    dists = F.softmax(attn_scores, -1)\n",
        "    attn_weighted_sum = torch.bmm(dists, x)\n",
        "\n",
        "    x = x + attn_weighted_sum\n",
        "\n",
        "    x = self.layer_norm(x.view(B, -1))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class SPRL(nn.Module):\n",
        "    def __init__(self,\n",
        "            vocab_size=None,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            shared_size=None,\n",
        "            padding_idx=None,\n",
        "            emb_np=None,\n",
        "            properties=None,\n",
        "            use_attention=False,\n",
        "            use_lstm=False,\n",
        "            direction_feature=False,\n",
        "            train_jointly=False,\n",
        "            eye=False,\n",
        "            updates_are_logits=False):\n",
        "        super(SPRL, self).__init__()\n",
        "\n",
        "        self.properties = properties\n",
        "        self.n_properties = len(properties)\n",
        "        self.direction_feature = direction_feature\n",
        "\n",
        "        self.word_emb = nn.Embedding(\n",
        "                vocab_size,\n",
        "                emb_size,\n",
        "                padding_idx=padding_idx)\n",
        "        self.word_emb.weight.data.copy_(torch.Tensor(emb_np))\n",
        "        self.word_emb.weight.requires_grad = False\n",
        "\n",
        "\n",
        "        self.lstm = None\n",
        "        if use_lstm:\n",
        "          self.use_lstm = True\n",
        "          directions = 2\n",
        "          if not train_jointly:\n",
        "            self.lstm = {}\n",
        "            for p in self.properties:\n",
        "              self.lstm[p] = MyLSTM(\n",
        "                emb_size=emb_size,\n",
        "                h_size=h_size,\n",
        "                directions=directions)\n",
        "          else:\n",
        "            self.lstm = MyLSTM(\n",
        "                emb_size=emb_size,\n",
        "                h_size=h_size,\n",
        "                directions=directions)\n",
        "\n",
        "          concatenated_embs_size = 2*(directions*h_size)\n",
        "        \n",
        "        else:\n",
        "          concatenated_embs_size = (2*emb_size) + int(direction_feature)\n",
        "\n",
        "        self.attention = None\n",
        "        if not use_attention:\n",
        "          shared_size = concatenated_embs_size\n",
        "          #shared_size = self.n_properties\n",
        "          self.shared = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "              nn.ReLU(),\n",
        "              )\n",
        "          self.prop_specific = nn.Sequential(\n",
        "              nn.Linear(shared_size, self.n_properties, bias=True),\n",
        "              )\n",
        "          \n",
        "          #self.clf = nn.Linear(self.n_properties*shared_size, self.n_properties, bias=True)\n",
        "          #self.clf = nn.Linear(shared_size, self.n_properties, bias=True)\n",
        "        else: # \"shared\" not really best name here...\n",
        "          self.attention = True\n",
        "          self.first_guess = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, self.n_properties, bias=True),\n",
        "              #nn.BatchNorm1d(self.n_properties, affine=False)\n",
        "              #nn.ReLU()\n",
        "              )\n",
        "          \n",
        "          self.updates_are_logits = updates_are_logits \n",
        "          \n",
        "          self.updates = nn.Linear(self.n_properties, self.n_properties, bias=True)\n",
        "          # self.updates = nn.Sequential(\n",
        "          #     nn.Linear(self.n_properties, self.n_properties, bias=True),\n",
        "          #     nn.ReLU(),\n",
        "          #     nn.Linear(self.n_properties, self.n_properties, bias=True)\n",
        "          #     )\n",
        "          \n",
        "          self.eye = eye\n",
        "          if self.eye:\n",
        "            self.updates.weight.data -= (torch.eye(self.n_properties) * self.updates.weight.data)\n",
        "\n",
        "\n",
        "    def forward(self, sents, sent_lens, preds, heads, updates=True):\n",
        "\n",
        "        # Sort the sentences so that the LSTM can process properly\n",
        "        B, _, = sents.shape\n",
        "\n",
        "\n",
        "        if self.lstm != None:\n",
        "          lens_sorted = sent_lens\n",
        "          sents_sorted = sents\n",
        "          indices = None\n",
        "          if(len(sents) > 1):\n",
        "              lens_sorted, indices = torch.sort(lens_sorted, descending=True)\n",
        "              lens_sorted = lens_sorted.to(device)\n",
        "              indices = indices.to(device)\n",
        "              sents_sorted = sents_sorted.index_select(0, indices).to(device)\n",
        "          w_embs = self.word_emb(sents_sorted)\n",
        "          packed_lstm_input = pack_padded_sequence(\n",
        "                  w_embs, lens_sorted, batch_first=True)\n",
        "\n",
        "          if type(self.lstm) == type(dict()):\n",
        "            lstm_outs = {p: self.lstm[p](packed_lstm_input, indices) for p in self.properties}\n",
        "            lstm_outs = torch.stack(list(lstm_outs.values()), dim=0).sum(0)\n",
        "          else:\n",
        "            lstm_outs = self.lstm(packed_lstm_input, indices)\n",
        "          pred_reps = lstm_outs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = lstm_outs[np.arange(B), heads] # same as above\n",
        "        else:\n",
        "          w_embs = self.word_emb(sents)\n",
        "          pred_reps = w_embs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = w_embs[np.arange(B), heads] # same as above\n",
        "\n",
        "        if self.direction_feature:\n",
        "          head_before_pred = torch.unsqueeze((preds > heads), -1).float() # (B,)\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps, head_before_pred], dim=-1) # (B, 2*h_size)\n",
        "        else:\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps], dim=-1) # (B, 2*h_size)\n",
        "\n",
        "        x = pred_head_cat\n",
        "        if self.attention == None:\n",
        "          x = pred_head_cat # Experimenting with having no shared and learned rep\n",
        "          x = self.shared(x) # (B, size_shared) # For lstm\n",
        "\n",
        "          logits = self.prop_specific(x)\n",
        "        else:\n",
        "          x = self.first_guess(x)\n",
        "          if updates:\n",
        "            if self.eye:\n",
        "              self.updates.weight.data -= (torch.eye(self.n_properties).to(device) * self.updates.weight.data)\n",
        "            x_up = self.updates(x) # \n",
        "\n",
        "            #logits = x + x_up # Residual model\n",
        "            if self.updates_are_logits:\n",
        "              logits = x_up\n",
        "            else:\n",
        "              logits = x + x_up # Residual model\n",
        "          else:\n",
        "            logits = x\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict(self, logits):\n",
        "        # That is to say, predict 0 if logit < 0 and 1 if logit >= 0\n",
        "        predictions = (logits.sign() + 1) / 2\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "class MyLSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            directions=None):\n",
        "        super(MyLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "                input_size=emb_size,    \n",
        "                hidden_size=h_size,\n",
        "                num_layers=1,\n",
        "                bidirectional=(directions == 2),\n",
        "                batch_first=True,\n",
        "                dropout=0.1,\n",
        "                bias=True)\n",
        "        \n",
        "        self.lstm_drop = nn.Dropout(0.)\n",
        "\n",
        "    def forward(self, packed_lstm_input, indices):\n",
        "        outputs, _ = self.lstm(packed_lstm_input)\n",
        "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "\n",
        "        # Unsort sentences to return to proper alignment with labels\n",
        "        if len(outputs) > 1:\n",
        "            outputs = unsort(outputs, indices)\n",
        "          \n",
        "        outputs = self.lstm_drop(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        " \n",
        "def unsort(batch, indices):\n",
        "    indices_inverted = torch.argsort(indices)\n",
        "    batch = batch.index_select(0, indices_inverted)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahYg0bRx-Xdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(args, model, X, y):\n",
        "    epochs = args['epochs']\n",
        "    batch_size = args['batch_size']\n",
        "    lr = args['lr']\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      if 'updates' in name and 'weight' in name:\n",
        "        original_weights = param.detach().clone()\n",
        "\n",
        "    # Data loaders\n",
        "    loader_train = data_loader(X['train'], y['train'],\n",
        "            batch_size=batch_size, shuffle_idx=True)\n",
        "    loader_dev = data_loader(X['dev'], y['dev'],\n",
        "            batch_size=batch_size, shuffle_idx=False)\n",
        "    n_train_batches = math.ceil(len(X['train']) / batch_size)\n",
        "    n_dev_batches = math.ceil(len(X['dev']) / batch_size)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = Adam(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "    #opt = AdamW(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "    #opt = LBFGS(model.parameters())\n",
        "\n",
        "    # Train loop\n",
        "    training_losses = []\n",
        "    dev_losses = [4]\n",
        "    steps = 0\n",
        "    cma = 0\n",
        "    try:\n",
        "      prev_best = 0.0\n",
        "      for e in range(epochs):\n",
        "        model.train()\n",
        "        steps_ = 0\n",
        "        for b in tqdm(\n",
        "                range(n_train_batches), \n",
        "                ascii=True, \n",
        "                desc=f'Epoch {e+1}/{epochs} progress',\n",
        "                position=0,\n",
        "                leave=True,\n",
        "                ncols=80):\n",
        "          opt.zero_grad()\n",
        "          sents, sent_lens, preds, heads, labels = next(loader_train)\n",
        "\n",
        "          if args['use_attention']:\n",
        "            stop_training_lower = e >= args['stop_training_lower']\n",
        "\n",
        "            #step_updates = e > 0 or steps_ > (n_train_batches / 2)\n",
        "            #if step_updates:\n",
        "            if stop_training_lower:\n",
        "              for p in model.parameters():\n",
        "                p.requires_grad = False\n",
        "              for p in model.updates.parameters():\n",
        "                p.requires_grad = True\n",
        "              \n",
        "              logits = model(sents, sent_lens, preds, heads)\n",
        "              # loss = bce_loss(logits, labels)\n",
        "              # loss.backward()\n",
        "              # opt.step()\n",
        "              # opt.zero_grad()\n",
        "\n",
        "            # Normal step\n",
        "            if not stop_training_lower:\n",
        "              for p in model.parameters():\n",
        "                p.requires_grad = True\n",
        "              for p in model.updates.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "                logits = model(sents, sent_lens, preds, heads, updates=False)\n",
        "              # if b == n_train_batches - 1:\n",
        "              #   print(logits[0])\n",
        "          \n",
        "          else: # Not attention\n",
        "            logits = model(sents, sent_lens, preds, heads)\n",
        "\n",
        "          loss = bce_loss(logits, labels)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "          steps_ += 1\n",
        "          cma = (loss.item() + (steps_-1) * cma) / steps_\n",
        "          training_losses.append(cma)\n",
        "        # end of batch loop\n",
        "        steps += steps_\n",
        "\n",
        "        predictions = get_test_predictions(model, X['dev'], y['dev'])\n",
        "        results, metrics = evaluate(args, predictions, y['dev'])\n",
        "        F, precision, recall = metrics['F'], metrics['precision'], metrics['recall']\n",
        "        #dev_losses.append(np.mean(dev_loss))\n",
        "        dev_losses.append(-1)\n",
        "\n",
        "        print(f\"Epoch {e}, F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "\n",
        "        if F > prev_best:\n",
        "          prev_best = F\n",
        "          torch.save(model.state_dict(), weights_path)\n",
        "\n",
        "        if args['use_attention'] and args['show_weights'] and e >=5:\n",
        "          for name, param in model.named_parameters():\n",
        "            if 'updates' in name and 'weight' in name:\n",
        "              updates_weights = param\n",
        "          with torch.no_grad():\n",
        "            show_weights((updates_weights - original_weights).cpu(), properties=model.properties)\n",
        "            #show_weights((updates_weights).cpu(), properties=model.properties)\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    # End of train loop\n",
        "\n",
        "    model.load_state_dict(torch.load(weights_path))\n",
        "    test_predictions = predictions = get_test_predictions(model, X['dev'], y['dev'])\n",
        "    CI = bootstrap_conf_interval(test_predictions, y['dev'])\n",
        "\n",
        "    print(f'\\n Confidence interval : {CI}\\n')\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=1)\n",
        "\n",
        "    ax[0].plot(np.arange(len(training_losses)), np.array(training_losses), color='orange')\n",
        "    ax[1].plot(np.arange(0, steps+1, n_train_batches), np.array(dev_losses), color='blue')\n",
        "    fig.show()\n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "def show_weights(weights, properties=None, cmap='RdBu'):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    norm = None\n",
        "    if cmap == 'RdBu':\n",
        "      vmax = weights.max()\n",
        "      vmin = weights.min()\n",
        "      if type(weights) == type(torch.randn(1)):\n",
        "        vmax = vmax.item()\n",
        "        vmin = vmin.item()\n",
        "      norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0)\n",
        "\n",
        "    ax.set_xticks(np.arange(len(properties)))\n",
        "    ax.set_yticks(np.arange(len(properties)))\n",
        "    ax.set_xticklabels(properties)\n",
        "    ax.set_yticklabels(properties)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode=\"anchor\")\n",
        "\n",
        "    if norm != None:\n",
        "      plt.imshow(weights, cmap=cmap, norm=norm)\n",
        "    else:\n",
        "      plt.imshow(weights, cmap=cmap)\n",
        "    cbar = plt.colorbar()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def bce_loss(logits, labels):\n",
        "    # Expected labels : (B, num_properties)\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def data_loader(X, y, batch_size=None, shuffle_idx=False):\n",
        "    data = list(zip(X, y))\n",
        "    idx = list(range(len(data)))\n",
        "    while True:\n",
        "        if shuffle_idx:\n",
        "            random.shuffle(idx) # In-place shuffle\n",
        "        \n",
        "        for span in idx_spans(idx, batch_size):\n",
        "            batch = [data[i] for i in span]\n",
        "            yield prepare_batch(batch)\n",
        "\n",
        "\n",
        "def idx_spans(idx, span_size):\n",
        "    for i in range(0, len(idx), span_size):\n",
        "        yield idx[i:i+span_size]\n",
        "\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    # batch[i] = X, y\n",
        "    batch_size = len(batch)\n",
        "    sent_lens = torch.LongTensor([len(x[0][0]) for x in batch])\n",
        "    max_length = torch.max(sent_lens).item()\n",
        "    n_properties = len(batch[0][1])\n",
        "\n",
        "    # Zero is padding index\n",
        "    sents = torch.zeros((batch_size, max_length)).long().to(device)\n",
        "    preds = torch.zeros(batch_size).long().to(device)\n",
        "    heads = torch.zeros(batch_size).long().to(device)\n",
        "    labels = torch.zeros(batch_size, n_properties).to(device)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(batch):\n",
        "        sent, (pred_idx, head_idx) = X_batch\n",
        "        sents[i,:len(sent)] = torch.LongTensor(sent)\n",
        "        preds[i] = pred_idx\n",
        "        heads[i] = head_idx\n",
        "        labels[i] = torch.tensor(y_batch)\n",
        "\n",
        "    return sents, sent_lens, preds, heads, labels\n",
        "\n",
        "\n",
        "            #old dev eval code\n",
        "          # with torch.no_grad():\n",
        "          #   model.eval()\n",
        "          #   tp = 0\n",
        "          #   fp = 0\n",
        "          #   fn = 0\n",
        "          #   dev_loss = 0\n",
        "          #   for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80, position=0, leave=True):\n",
        "          #     sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "          #     results_, metrics_, dev_loss_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "          #     tp += results_['tp']\n",
        "          #     fp += results_['fp']\n",
        "          #     fn += results_['fn']\n",
        "          #     dev_loss += dev_loss_.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyxihDMkczmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def evaluate(args, model, sents, sent_lens, preds, heads, labels):\n",
        "#     # Get predictions\n",
        "#     logits = model(sents, sent_lens, preds, heads)\n",
        "#     dev_loss = bce_loss(logits, labels)\n",
        "#     predictions = model.predict(logits)\n",
        "\n",
        "#     predictions, labels = predictions.cpu().numpy(), labels.cpu().numpy()\n",
        "#     results, metrics = get_results_metrics(predictions, labels)\n",
        "\n",
        "#     return results, metrics, dev_loss\n",
        "\n",
        "\n",
        "def evaluate(args, predictions, labels):\n",
        "    # Get predictions\n",
        "    labels = np.array(labels)\n",
        "    predictions, labels = predictions.cpu().numpy(), labels\n",
        "    results, metrics = get_results_metrics(predictions, labels)\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "\n",
        "def get_results_metrics(predictions, labels):\n",
        "    n_correct = (predictions == labels).astype(int).sum()\n",
        "\n",
        "    # Precision, Recall\n",
        "    eq = predictions == labels\n",
        "    neq = predictions != labels\n",
        "\n",
        "    pos_preds = predictions == 1\n",
        "    neg_preds = predictions == 0\n",
        "\n",
        "    tp = np.where(pos_preds, eq, 0).astype(int).sum()\n",
        "    fp = np.where(pos_preds, neq, 0).astype(int).sum()\n",
        "    fn = np.where(neg_preds, neq, 0).astype(int).sum()\n",
        "    \n",
        "    results = {\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'fn': fn\n",
        "            }\n",
        "\n",
        "    F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "    metrics = {'F': F, 'precision': precision, 'recall': recall}\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "\n",
        "def F_precision_recall(tp, fp, fn):\n",
        "    if tp + fp > 0.:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0.\n",
        "\n",
        "    if tp + fn > 0.:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0.\n",
        "\n",
        "    if precision + recall > 0.:\n",
        "        F = (2 * precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        F = 0.\n",
        "\n",
        "    return F, precision, recall\n",
        "\n",
        "\n",
        "def micro_average(results):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    for v in results.values():\n",
        "        tp += v['tp']\n",
        "        fp += v['fp']\n",
        "        fn += v['fn']\n",
        "    \n",
        "    return F_precision_recall(tp, fp, fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuRNj885-f2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5YvM4uHvsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(args):\n",
        "    df = pd.read_csv(PROTO_TSV, sep='\\t')\n",
        "\n",
        "    # Sentences\n",
        "    sent_ids = set(df['Sentence.ID'].tolist())\n",
        "    sents_path = os.path.join(PICKLED_DIR, 'sents.pkl')\n",
        "    sents = None\n",
        "    with open(sents_path, 'rb') as f:\n",
        "      sents = pickle.load(f)\n",
        "\n",
        "    # Dependency data\n",
        "    # dependencies_path = os.path.join(PICKLED_DIR, 'dependencies.pkl')\n",
        "    # with open(dependencies_path, 'rb') as f:\n",
        "    #     deps, deps_just_tokens = pickle.load(f)  \n",
        "    # sents['dependencies'] = deps\n",
        "    # sents['deps_just_tokens'] = deps_just_tokens\n",
        "\n",
        "\n",
        "    # Instances\n",
        "    path = os.path.join(PICKLED_DIR, 'instances.pkl')\n",
        "    proto_instances = None\n",
        "    possible = None # Data to compare to SPRL paper\n",
        "    with open(path, 'rb') as f:\n",
        "      proto_instances, possible = pickle.load(f)\n",
        "\n",
        "    # Word embedding data\n",
        "    w2e = None\n",
        "    path = os.path.join(PICKLED_DIR, f\"glove_{args['glove_d']}.pkl\")\n",
        "    with open(path, 'rb') as f:\n",
        "      w2e = pickle.load(f)\n",
        "\n",
        "    w2i, i2w = None, None\n",
        "    emb_np = None\n",
        "    X, y = None, None\n",
        "    dicts_path = os.path.join(PICKLED_DIR, 'dicts.pkl')\n",
        "    with open(dicts_path, 'rb') as f:\n",
        "        w2i, i2w = pickle.load(f)\n",
        "    \n",
        "    emb_np_path = os.path.join(PICKLED_DIR, 'emb_np.pkl')\n",
        "    with open(emb_np_path, 'rb') as f:\n",
        "        emb_np = pickle.load(f)\n",
        "    \n",
        "    lstm_data_path = os.path.join(PICKLED_DIR, 'lstm_data.pkl')\n",
        "    with open(lstm_data_path, 'rb') as f:\n",
        "        X, y = pickle.load(f)\n",
        "\n",
        "    return {'df': df, \n",
        "            'proto_instances': proto_instances, \n",
        "            'possible': possible,\n",
        "            'sents': sents,\n",
        "            'w2e': w2e,\n",
        "            'sent_ids': sent_ids,\n",
        "            'lstm_data': (X,y),\n",
        "            'dicts': (w2i, i2w),\n",
        "            'emb_np': emb_np}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erm6Foa6jWJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def co_occurrences(y_train, normalize=False):\n",
        "  n_props = y_train[0].shape[0]\n",
        "\n",
        "  co_occur = np.zeros((n_props, n_props))\n",
        "  anti_occur = np.zeros((n_props, n_props))\n",
        "  both_negative = np.zeros((n_props, n_props))\n",
        "  row_pos_col_neg = np.zeros((n_props, n_props))\n",
        "  row_neg_col_pos = np.zeros((n_props, n_props))\n",
        "\n",
        "  positive_counts = np.zeros(n_props)\n",
        "  for labels in y_train:\n",
        "    for i in range(n_props):\n",
        "      if labels[i] == 1:\n",
        "        positive_counts[i] += 1\n",
        "        for j in range(i+1, n_props):\n",
        "          if labels[j] == 1:\n",
        "            co_occur[i,j] += 1\n",
        "\n",
        "        for j in range(n_props):\n",
        "          if labels[j] == 0:\n",
        "            row_pos_col_neg[i,j] += 1\n",
        "        \n",
        "      else: # labels[i] == 0\n",
        "        for j in range(i+1, n_props):\n",
        "          if labels[j] == 0:\n",
        "            both_negative[i,j] += 1\n",
        "        \n",
        "        for j in range(n_props):\n",
        "          if labels[j] == 1:\n",
        "            row_neg_col_pos[i,j] += 1\n",
        "  \n",
        "  negative_counts = len(y_train) - positive_counts\n",
        "\n",
        "  # Mirror over diagonal\n",
        "  co_occur = co_occur + np.transpose(co_occur)\n",
        "  both_negative = both_negative + np.transpose(both_negative)\n",
        "  #anti_occur = anti_occur + np.transpose(anti_occur)\n",
        "\n",
        "  def normalize_rows(array):\n",
        "    array /= np.sum(array, axis=-1, keepdims=True)\n",
        "\n",
        "  positive_counts = np.expand_dims(positive_counts, axis=-1)\n",
        "\n",
        "  # all_ = co_occur + both_negative + row_neg_col_pos + row_pos_col_neg\n",
        "  # print(all_)\n",
        "  # breakpoint()\n",
        "\n",
        "  if normalize:\n",
        "    #co_occur /= positive_counts\n",
        "    normalize_rows(co_occur)\n",
        "    #row_pos_col_neg /= positive_counts\n",
        "    normalize_rows(row_neg_col_pos)\n",
        "\n",
        "\n",
        "\n",
        "  #print(f'Now max of anti_occur is {np.max(anti_occur)}, compared to {np.max(negative_counts)}')\n",
        "  \n",
        "\n",
        "  return co_occur, both_negative, row_pos_col_neg, row_neg_col_pos\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNVWhg68C0iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MidpointNormalize(mpl.colors.Normalize):\n",
        "    def __init__(self, vmin, vmax, midpoint=0, clip=False):\n",
        "        self.midpoint = midpoint\n",
        "        mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
        "\n",
        "    def __call__(self, value, clip=None):\n",
        "        normalized_min = max(0, 1 / 2 * (1 - abs((self.midpoint - self.vmin) / (self.midpoint - self.vmax))))\n",
        "        normalized_max = min(1, 1 / 2 * (1 + abs((self.vmax - self.midpoint) / (self.midpoint - self.vmin))))\n",
        "        normalized_mid = 0.5\n",
        "        x, y = [self.vmin, self.midpoint, self.vmax], [normalized_min, normalized_mid, normalized_max]\n",
        "        return sp.ma.masked_array(sp.interp(value, x, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1On2T0rcKKwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bootstrap_conf_interval(predictions, labels, B=10000):\n",
        "  predictions = predictions.cpu().numpy() # (n_test,18)\n",
        "  N = predictions.shape[0]\n",
        "  indices = np.arange(N)\n",
        "  \n",
        "  labels = np.array(labels)\n",
        "\n",
        "  bs_samples = []\n",
        "  for b in tqdm(range(B), desc='Getting bootstrap samples', ncols=80, position=0, leave=True):\n",
        "    idx = np.random.choice(indices, N)\n",
        "    curr_preds = predictions[idx]\n",
        "    curr_labels = labels[idx]\n",
        "    results, metrics = get_results_metrics(curr_preds, curr_labels)\n",
        "    micro_f1 = metrics['F']\n",
        "    bs_samples.append(micro_f1)\n",
        "\n",
        "  plt.hist(bs_samples)\n",
        "  \n",
        "  return np.quantile(bs_samples, [0.025, 0.975])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7fJuKWbmsJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_predictions(model, X_test, y_test, batch_size=100):\n",
        "\n",
        "  loader_test = data_loader(X_test, y_test, batch_size=batch_size, shuffle_idx=False)\n",
        "\n",
        "  n_batches = math.ceil(len(X_test) / batch_size)\n",
        "\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for b in tqdm(range(n_batches), ascii=True, desc=f'Getting test predictions', ncols=80, position=0, leave=True):\n",
        "      sents, sent_lens, preds, heads, _ = next(loader_test)\n",
        "      logits = model(sents, sent_lens, preds, heads)\n",
        "      predictions.append(model.predict(logits))\n",
        "  \n",
        "  predictions = torch.cat(predictions, dim=0)\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUbR-mhy-dRb",
        "colab_type": "code",
        "outputId": "18f6fe1e-92d7-4a29-9256-3f3e5797c76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args = {\n",
        "    'epochs': 10,\n",
        "    'seed': 7,\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 100,\n",
        "    'h_size': 100,\n",
        "    #'shared_size': 300,\n",
        "    'glove_d': 300,\n",
        "    'use_attention': False,\n",
        "    'use_lstm': True,\n",
        "    'train_jointly': True, # Train the lstm jointly\n",
        "\n",
        "    'show_weights': False,\n",
        "\n",
        "    'stop_training_lower': 5,\n",
        "    'eye':True,\n",
        "    'updates_are_logits':False\n",
        "}\n",
        "\n",
        "seed = args['seed']\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "data = get_data(args)\n",
        "\n",
        "w2i, i2w = data['dicts']\n",
        "emb_np = data['emb_np']\n",
        "X, y = data['lstm_data']\n",
        "\n",
        "# co_occur, both_negative, row_pos_col_neg, row_neg_col_pos = co_occurrences(y['train'], normalize=False)\n",
        "# show_weights(co_occur + both_negative, properties=PROPERTIES, cmap='Greens')\n",
        "# show_weights(row_pos_col_neg + row_neg_col_pos, properties=PROPERTIES, cmap='Reds')\n",
        "# show_weights((co_occur + both_negative) - (row_pos_col_neg + row_neg_col_pos), properties=PROPERTIES)\n",
        "#breakpoint()\n",
        "\n",
        "model = SPRL(\n",
        "    vocab_size=len(w2i),\n",
        "    emb_size=int(args['glove_d']),\n",
        "    h_size=args['h_size'],\n",
        "    #shared_size=args['shared_size'],\n",
        "    padding_idx=w2i[PAD_TOKEN],\n",
        "    emb_np=emb_np,\n",
        "    properties=PROPERTIES,\n",
        "    use_attention=args['use_attention'],\n",
        "    use_lstm=args['use_lstm'],\n",
        "    direction_feature=not args['use_lstm'],\n",
        "    train_jointly=args['train_jointly'],\n",
        "    eye=args['eye'],\n",
        "    updates_are_logits=args['updates_are_logits'])\n",
        "model.to(device)\n",
        "\n",
        "train(args, model, X, y)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Epoch 1/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.88it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 31.25it/s]\n",
            "Epoch 2/10 progress:   0%|                               | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, F=73.22, p=78.35, r=68.72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10 progress: 100%|######################| 78/78 [00:04<00:00, 16.08it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 31.88it/s]\n",
            "Epoch 3/10 progress:   3%|5                      | 2/78 [00:00<00:04, 15.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, F=77.18, p=81.18, r=73.56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10 progress: 100%|######################| 78/78 [00:04<00:00, 16.15it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 31.60it/s]\n",
            "Epoch 4/10 progress:   3%|5                      | 2/78 [00:00<00:04, 16.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, F=78.65, p=80.96, r=76.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.95it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 32.95it/s]\n",
            "Epoch 5/10 progress:   3%|5                      | 2/78 [00:00<00:04, 16.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, F=80.15, p=81.92, r=78.45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.98it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 31.74it/s]\n",
            "Epoch 6/10 progress:   0%|                               | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, F=80.64, p=82.05, r=79.29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.87it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 32.10it/s]\n",
            "Epoch 7/10 progress:   3%|5                      | 2/78 [00:00<00:04, 16.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, F=80.73, p=82.26, r=79.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.62it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 26.64it/s]\n",
            "Epoch 8/10 progress:   3%|5                      | 2/78 [00:00<00:04, 15.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, F=81.13, p=82.50, r=79.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.79it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 30.11it/s]\n",
            "Epoch 9/10 progress:   3%|5                      | 2/78 [00:00<00:06, 12.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, F=80.70, p=81.58, r=79.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10 progress: 100%|######################| 78/78 [00:04<00:00, 15.78it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 32.19it/s]\n",
            "Epoch 10/10 progress:   3%|5                     | 2/78 [00:00<00:05, 15.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, F=80.43, p=81.51, r=79.38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10 progress: 100%|#####################| 78/78 [00:04<00:00, 15.79it/s]\n",
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 26.93it/s]\n",
            "Getting test predictions:  40%|#######2          | 4/10 [00:00<00:00, 32.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, F=80.31, p=80.47, r=80.15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting test predictions: 100%|#################| 10/10 [00:00<00:00, 31.56it/s]\n",
            "Getting bootstrap samples: 100%|████████| 10000/10000 [00:06<00:00, 1645.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Confidence interval : [0.79877139 0.82356196]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}