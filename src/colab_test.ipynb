{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "colab_test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POJfkUeHELGD",
        "colab_type": "code",
        "outputId": "6e840599-3cdb-40dc-be8a-6247a5750e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWk4rHFeGXuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/proto_data/'\n",
        "PICKLED_DIR = os.path.join(DATA_DIR, 'pickled/')\n",
        "#CONLLU_DIR = os.path.join(DATA_DIR, 'WSJ_conllus/')\n",
        "#MODEL_DIR = '../saved_models/'\n",
        "\n",
        "PROTO_TSV = os.path.join(DATA_DIR, 'protoroles_eng_pb_08302015.tsv')\n",
        "#GLOVE_FILE = {'100': os.path.join(DATA_DIR, 'glove.6B.100d.txt') }\n",
        "\n",
        "SPLITS = ['train', 'dev', 'test'] \n",
        "\n",
        "PROPERTIES = ['instigation', 'volition', 'awareness', 'sentient',\n",
        "'exists_as_physical', 'existed_before', 'existed_during', 'existed_after',\n",
        "'created', 'destroyed', 'predicate_changed_argument', 'change_of_state', \n",
        "'changes_possession', 'change_of_location', 'stationary', 'location_of_event', \n",
        "'makes_physical_contact', 'manipulated_by_another']\n",
        "\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUBxnzAlVE9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/proto_modules')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wGdMdn8tTO",
        "colab_type": "code",
        "outputId": "22a873c2-28b1-4e34-c331-614fe2a74f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)\n",
        "\n",
        "#import data_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IAS8EuYvxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import unsqueeze\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, \\\n",
        "        pack_padded_sequence, pad_sequence\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "            vocab_size=None,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            shared_size=None,\n",
        "            padding_idx=None,\n",
        "            emb_np=None,\n",
        "            properties=None):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.n_properties=len(properties)\n",
        "\n",
        "        self.word_emb = nn.Embedding(\n",
        "                vocab_size,\n",
        "                emb_size,\n",
        "                padding_idx=padding_idx)\n",
        "        self.word_emb.weight.data.copy_(torch.Tensor(emb_np))\n",
        "        self.word_emb.weight.requires_grad = False\n",
        "        \n",
        "        directions = 2\n",
        "        self.lstm = nn.LSTM(\n",
        "                input_size=emb_size,    \n",
        "                hidden_size=h_size,\n",
        "                num_layers=1,\n",
        "                bidirectional=(directions == 2),\n",
        "                batch_first=True,\n",
        "                dropout=0.1,\n",
        "                bias=True)\n",
        "        \n",
        "        self.lstm_drop = nn.Dropout(0.)\n",
        "        \n",
        "        concatenated_embs_size = 2*(directions*h_size) # If using LSTM\n",
        "        #concatenated_embs_size = (2*emb_size) # If using DAN\n",
        "        shared_size=concatenated_embs_size\n",
        "        specific_size = int(shared_size / 2)\n",
        "\n",
        "        # IF using LSTM\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "        #    nn.Dropout(0.2),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        # DAN\n",
        "        # self.shared = nn.Sequential(\n",
        "        #     nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(shared_size, shared_size, bias=True),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(shared_size, shared_size, bias=True),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.ReLU())\n",
        "\n",
        "        # Attention-based\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(self.n_properties*concatenated_embs_size, self.n_properties * specific_size, bias=True),\n",
        "        #    nn.Dropout(0.2),\n",
        "            nn.ReLU())\n",
        "        \n",
        "\n",
        "\n",
        "        # Output is (B, shared_size)\n",
        "\n",
        "        #self.mlps = {p: nn.Linear(2 * h_size, 2) for p in PROPERTIES}\n",
        "        self.mlp = nn.Linear(shared_size*self.n_properties, self.n_properties, bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, sents, sent_lens, preds, heads):\n",
        "\n",
        "        # Sort the sentences so that the LSTM can process properly\n",
        "        lens_sorted = sent_lens\n",
        "        words_sorted = sents\n",
        "        indices = None\n",
        "        if(len(sents) > 1):\n",
        "            lens_sorted, indices = torch.sort(lens_sorted, descending=True)\n",
        "            lens_sorted = lens_sorted.to(device)\n",
        "            indices = indices.to(device)\n",
        "            words_sorted = words_sorted.index_select(0, indices).to(device)\n",
        "\n",
        "        w_embs = self.word_emb(words_sorted)\n",
        "\n",
        "        packed_lstm_input = pack_padded_sequence(\n",
        "                w_embs, lens_sorted, batch_first=True)\n",
        "\n",
        "        outputs, _ = self.lstm(packed_lstm_input)\n",
        "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "\n",
        "        # Unsort sentences to return to proper alignment with labels\n",
        "        if len(outputs) > 1:\n",
        "            outputs = unsort(outputs, indices)\n",
        "          \n",
        "        outputs = self.lstm_drop(outputs)\n",
        "\n",
        "        # outputs : (B, L, h_size), assuming preds (B)\n",
        "        B, L, h_size = outputs.shape\n",
        "        pred_reps = outputs[np.arange(B), preds] # expecting (B, h_size)\n",
        "        head_reps = outputs[np.arange(B), heads] # same as above\n",
        "\n",
        "        # DAN version\n",
        "        # outputs = self.word_emb(sents)\n",
        "        # B, L, h_size = outputs.shape\n",
        "        # pred_reps = outputs[np.arange(B), preds] # expecting (B, h_size)\n",
        "        # head_reps = outputs[np.arange(B), heads] # same as above\n",
        "\n",
        "        # Get pred-arg representation (same for DAN and LSTM)\n",
        "        shared_input = torch.cat([pred_reps, head_reps], dim=-1) # (B, 2*h_size)\n",
        "\n",
        "        #mlp_input = self.shared(shared_input) # (B, size_shared) # For lstm\n",
        "        #mlp_input = shared_input # (B, size_shared)\n",
        "        mlp_input = self.shared(shared_input.repeat(1, self.n_properties)) # (B, n_properties * size_specific) # For attn\n",
        "\n",
        "        reshaped = mlp_input.view(B, self.n_properties, -1)\n",
        "        print(f'reshaped shape {reshaped.shape}')\n",
        "\n",
        "        attn_scores = torch.bmm(reshaped, torch.transpose(reshaped, 2, 1))\n",
        "        #print(f'Attnscores shape {attn_scores.shape}')\n",
        "        dists = F.softmax(attn_scores, -1)\n",
        "        #print(f'dists shape {dists.shape}')\n",
        "        # sums = dists.sum(-1)\n",
        "        # print(sums.shape)\n",
        "        # print(sums.sum())\n",
        "\n",
        "        # Zero out self-attn score? Prob equiv to zeroing + adding original vector back\n",
        "\n",
        "        # Now get attention-weighted sum for each prop -> (B, n_properties, specific_size)\n",
        "\n",
        "        # Then choose: concatenate or sum orig & attn-weighted sum\n",
        "\n",
        "        # Finally, \n",
        "        breakpoint()\n",
        "\n",
        "        #logits = {p: None for p in PROPERTIES}\n",
        "        #for p in PROPERTIES:\n",
        "        #    logits[p] = self.mlps[p](mlp_input)\n",
        "\n",
        "        mlp_input = mlp_input.repeat(1, self.n_properties) # Don't repeat on axis 0, \n",
        "        logits = self.mlp(mlp_input) # (B, properties)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "        \n",
        "    def predict(self, sents, sent_lens, preds, heads):\n",
        "\n",
        "        logits = self.forward(sents, sent_lens, preds, heads)\n",
        "        predictions = (logits.sign() + 1) / 2\n",
        "        #preds = F.sigmoid(logits)\n",
        "        #preds = argmax(logits, -1) # assuming logits a (num_props X 2) array\n",
        "\n",
        "        return predictions\n",
        " \n",
        "def unsort(batch, indices):\n",
        "    indices_inverted = torch.argsort(indices)\n",
        "    batch = batch.index_select(0, indices_inverted)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahYg0bRx-Xdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_lstm(args, model, X, y):\n",
        "    epochs = args['epochs']\n",
        "    batch_size = args['batch_size']\n",
        "    lr = args['lr']\n",
        "\n",
        "\n",
        "    # Data loaders\n",
        "    loader_train = data_loader(X['train'], y['train'],\n",
        "            batch_size=batch_size, shuffle_idx=True)\n",
        "    loader_dev = data_loader(X['dev'], y['dev'],\n",
        "            batch_size=batch_size, shuffle_idx=False)\n",
        "    n_train_batches = math.ceil(len(X['train']) / batch_size)\n",
        "    n_dev_batches = math.ceil(len(X['dev']) / batch_size)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = Adam(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "\n",
        "    # Train loop\n",
        "    try:\n",
        "        for e in range(epochs):\n",
        "            model.train()\n",
        "            for b in tqdm(\n",
        "                    range(n_train_batches), \n",
        "                    ascii=True, \n",
        "                    desc=f'Epoch {e+1}/{epochs} progress', \n",
        "                    ncols=80):\n",
        "                opt.zero_grad()\n",
        "                sents, sent_lens, preds, heads, labels = next(loader_train)\n",
        "                logits = model(sents, sent_lens, preds, heads)\n",
        "                loss = bce_loss(logits, labels)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "        \n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              tp = 0\n",
        "              fp = 0\n",
        "              fn = 0\n",
        "              for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80):\n",
        "                sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "                results_, metrics_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "                tp += results_['tp']\n",
        "                fp += results_['fp']\n",
        "                fn += results_['fn']\n",
        "              \n",
        "              F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "\n",
        "              print(f\"Epoch {e}, F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    # End of train loop\n",
        "\n",
        "    # Eval time!\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tp = 0\n",
        "      fp = 0\n",
        "      fn = 0\n",
        "      for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80):\n",
        "        sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "        results_, metrics_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "        tp += results_['tp']\n",
        "        fp += results_['fp']\n",
        "        fn += results_['fn']\n",
        "      \n",
        "      F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "\n",
        "      print(f\"F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "def bce_loss(logits, labels):\n",
        "    # Expected labels : (B, num_properties)\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def data_loader(X, y, batch_size=None, shuffle_idx=False):\n",
        "    data = list(zip(X, y))\n",
        "    idx = list(range(len(data)))\n",
        "    while True:\n",
        "        if shuffle_idx:\n",
        "            random.shuffle(idx) # In-place shuffle\n",
        "        \n",
        "        for span in idx_spans(idx, batch_size):\n",
        "            batch = [data[i] for i in span]\n",
        "            yield prepare_batch(batch)\n",
        "\n",
        "\n",
        "def idx_spans(idx, span_size):\n",
        "    for i in range(0, len(idx), span_size):\n",
        "        yield idx[i:i+span_size]\n",
        "\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    # batch[i] = X, y\n",
        "    batch_size = len(batch)\n",
        "    sent_lens = torch.LongTensor([len(x[0][0]) for x in batch])\n",
        "    max_length = torch.max(sent_lens).item()\n",
        "    n_properties = len(batch[0][1])\n",
        "\n",
        "    # Zero is padding index\n",
        "    sents = torch.zeros((batch_size, max_length)).long().to(device)\n",
        "    preds = torch.zeros(batch_size).long().to(device)\n",
        "    heads = torch.zeros(batch_size).long().to(device)\n",
        "    labels = torch.zeros(batch_size, n_properties).to(device)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(batch):\n",
        "        sent, (pred_idx, head_idx) = X_batch\n",
        "        sents[i,:len(sent)] = torch.LongTensor(sent)\n",
        "        preds[i] = pred_idx\n",
        "        heads[i] = head_idx\n",
        "        labels[i] = torch.tensor(y_batch)\n",
        "\n",
        "    return sents, sent_lens, preds, heads, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyxihDMkczmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(args, model, sents, sent_lens, preds, heads, labels):\n",
        "    # Get predictions\n",
        "    predictions = model.predict(sents, sent_lens, preds, heads)\n",
        "\n",
        "    predictions, labels = predictions.cpu().numpy(), labels.cpu().numpy()\n",
        "    n_correct = (predictions == labels).astype(int).sum()\n",
        "\n",
        "    # Precision, Recall\n",
        "    eq = predictions == labels\n",
        "    neq = predictions != labels\n",
        "\n",
        "    pos_preds = predictions == 1\n",
        "    neg_preds = predictions == 0\n",
        "\n",
        "    tp = np.where(pos_preds, eq, 0).astype(int).sum()\n",
        "    fp = np.where(pos_preds, neq, 0).astype(int).sum()\n",
        "    fn = np.where(neg_preds, neq, 0).astype(int).sum()\n",
        "    \n",
        "    results = {\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'fn': fn\n",
        "            }\n",
        "\n",
        "    F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "    metrics = {'F': F, 'precision': precision, 'recall': recall}\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "\n",
        "def F_precision_recall(tp, fp, fn):\n",
        "    if tp + fp > 0.:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0.\n",
        "\n",
        "    if tp + fn > 0.:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0.\n",
        "\n",
        "    if precision + recall > 0.:\n",
        "        F = (2 * precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        F = 0.\n",
        "\n",
        "    return F, precision, recall\n",
        "\n",
        "\n",
        "def micro_average(results):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    for v in results.values():\n",
        "        tp += v['tp']\n",
        "        fp += v['fp']\n",
        "        fn += v['fn']\n",
        "    \n",
        "    return F_precision_recall(tp, fp, fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5YvM4uHvsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(args):\n",
        "    df = pd.read_csv(PROTO_TSV, sep='\\t')\n",
        "\n",
        "    # Sentences\n",
        "    sent_ids = set(df['Sentence.ID'].tolist())\n",
        "    sents_path = os.path.join(PICKLED_DIR, 'sents.pkl')\n",
        "    sents = None\n",
        "    with open(sents_path, 'rb') as f:\n",
        "      sents = pickle.load(f)\n",
        "\n",
        "    # Dependency data\n",
        "    # dependencies_path = os.path.join(PICKLED_DIR, 'dependencies.pkl')\n",
        "    # with open(dependencies_path, 'rb') as f:\n",
        "    #     deps, deps_just_tokens = pickle.load(f)  \n",
        "    # sents['dependencies'] = deps\n",
        "    # sents['deps_just_tokens'] = deps_just_tokens\n",
        "\n",
        "\n",
        "    # Instances\n",
        "    path = os.path.join(PICKLED_DIR, 'instances.pkl')\n",
        "    proto_instances = None\n",
        "    possible = None # Data to compare to SPRL paper\n",
        "    with open(path, 'rb') as f:\n",
        "      proto_instances, possible = pickle.load(f)\n",
        "\n",
        "    # Word embedding data\n",
        "    w2e = None\n",
        "    path = os.path.join(PICKLED_DIR, f\"glove_{args['glove_d']}.pkl\")\n",
        "    with open(path, 'rb') as f:\n",
        "      w2e = pickle.load(f)\n",
        "\n",
        "    w2i, i2w = None, None\n",
        "    emb_np = None\n",
        "    X, y = None, None\n",
        "    dicts_path = os.path.join(PICKLED_DIR, 'dicts.pkl')\n",
        "    with open(dicts_path, 'rb') as f:\n",
        "        w2i, i2w = pickle.load(f)\n",
        "    \n",
        "    emb_np_path = os.path.join(PICKLED_DIR, 'emb_np.pkl')\n",
        "    with open(emb_np_path, 'rb') as f:\n",
        "        emb_np = pickle.load(f)\n",
        "    \n",
        "    lstm_data_path = os.path.join(PICKLED_DIR, 'lstm_data.pkl')\n",
        "    with open(lstm_data_path, 'rb') as f:\n",
        "        X, y = pickle.load(f)\n",
        "\n",
        "    return {'df': df, \n",
        "            'proto_instances': proto_instances, \n",
        "            'possible': possible,\n",
        "            'sents': sents,\n",
        "            'w2e': w2e,\n",
        "            'sent_ids': sent_ids,\n",
        "            'lstm_data': (X,y),\n",
        "            'dicts': (w2i, i2w),\n",
        "            'emb_np': emb_np}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUbR-mhy-dRb",
        "colab_type": "code",
        "outputId": "6a707dfe-fb4a-4a49-fa90-c6d2a101dd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "args = {\n",
        "    'epochs': 20,\n",
        "    'seed': 7,\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 100,\n",
        "    'h_size': 300,\n",
        "    #'shared_size': 300,\n",
        "    'glove_d': 300\n",
        "}\n",
        "\n",
        "seed = args['seed']\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "data = get_data(args)\n",
        "\n",
        "w2i, i2w = data['dicts']\n",
        "emb_np = data['emb_np']\n",
        "X, y = data['lstm_data']\n",
        "\n",
        "model = LSTM(\n",
        "                vocab_size=len(w2i),\n",
        "                emb_size=int(args['glove_d']),\n",
        "                h_size=args['h_size'],\n",
        "                #shared_size=args['shared_size'],\n",
        "                padding_idx=w2i[PAD_TOKEN],\n",
        "                emb_np=emb_np,\n",
        "                properties=PROPERTIES)\n",
        "model.to(device)\n",
        "\n",
        "train_lstm(args, model, X, y)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Epoch 1/20 progress:   0%|                               | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reshaped shape torch.Size([100, 18, 600])\n",
            "Attnscores shape torch.Size([100, 18, 18])\n",
            "dists shape torch.Size([100, 18, 18])\n",
            "torch.Size([100, 18])\n",
            "tensor(1800., device='cuda:0', grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-5b0d6328b5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-a5ac95177935>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(args, model, X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-c79c4dad266d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sents, sent_lens, preds, heads)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m#logits = {p: None for p in PROPERTIES}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'breakpoint' is not defined"
          ]
        }
      ]
    }
  ]
}