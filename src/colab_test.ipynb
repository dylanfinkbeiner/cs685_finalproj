{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "colab_test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POJfkUeHELGD",
        "colab_type": "code",
        "outputId": "2133be9b-891b-43fd-afc8-3e6e8a6d6506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWk4rHFeGXuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/proto_data/'\n",
        "PICKLED_DIR = os.path.join(DATA_DIR, 'pickled/')\n",
        "#CONLLU_DIR = os.path.join(DATA_DIR, 'WSJ_conllus/')\n",
        "#MODEL_DIR = '../saved_models/'\n",
        "\n",
        "PROTO_TSV = os.path.join(DATA_DIR, 'protoroles_eng_pb_08302015.tsv')\n",
        "#GLOVE_FILE = {'100': os.path.join(DATA_DIR, 'glove.6B.100d.txt') }\n",
        "\n",
        "SPLITS = ['train', 'dev', 'test'] \n",
        "\n",
        "PROPERTIES = ['instigation', 'volition', 'awareness', 'sentient',\n",
        "'exists_as_physical', 'existed_before', 'existed_during', 'existed_after',\n",
        "'created', 'destroyed', 'predicate_changed_argument', 'change_of_state', \n",
        "'changes_possession', 'change_of_location', 'stationary', 'location_of_event', \n",
        "'makes_physical_contact', 'manipulated_by_another']\n",
        "\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUBxnzAlVE9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/proto_modules')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wGdMdn8tTO",
        "colab_type": "code",
        "outputId": "c6b75944-3041-4230-98aa-c5692c9c2036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)\n",
        "\n",
        "#import data_utils"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IAS8EuYvxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import unsqueeze\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, \\\n",
        "        pack_padded_sequence, pad_sequence\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self,\n",
        "               n_properties=None,\n",
        "               specific_size=None):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.n_properties = n_properties\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.n_properties * specific_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = x.shape[0]\n",
        "\n",
        "    x = x.view(B, self.n_properties, -1) # (B, n_props, size_specific)\n",
        "\n",
        "    attn_scores = torch.bmm(x, torch.transpose(x, 2, 1)) # (B, n_props, n_props)\n",
        "    dists = F.softmax(attn_scores, -1)\n",
        "    attn_weighted_sum = torch.bmm(dists, x)\n",
        "\n",
        "    x = x + attn_weighted_sum\n",
        "\n",
        "    x = self.layer_norm(x.view(B, -1))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class SPRL(nn.Module):\n",
        "    def __init__(self,\n",
        "            vocab_size=None,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            shared_size=None,\n",
        "            padding_idx=None,\n",
        "            emb_np=None,\n",
        "            properties=None,\n",
        "            use_attention=True,\n",
        "            use_lstm=False,\n",
        "            direction_feature=False):\n",
        "        super(SPRL, self).__init__()\n",
        "\n",
        "        self.properties = properties\n",
        "        self.n_properties = len(properties)\n",
        "        self.direction_feature = direction_feature\n",
        "\n",
        "        self.word_emb = nn.Embedding(\n",
        "                vocab_size,\n",
        "                emb_size,\n",
        "                padding_idx=padding_idx)\n",
        "        self.word_emb.weight.data.copy_(torch.Tensor(emb_np))\n",
        "        self.word_emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = None\n",
        "        if use_lstm:\n",
        "          self.use_lstm = True\n",
        "          directions = 2\n",
        "          self.lstm = MyLSTM(\n",
        "              emb_size=emb_size,\n",
        "              h_size=h_size,\n",
        "              directions=directions,\n",
        "              properties=properties)\n",
        "\n",
        "          concatenated_embs_size = 2*(directions*h_size)\n",
        "        \n",
        "        else:\n",
        "          concatenated_embs_size = (2*emb_size) + int(direction_feature)\n",
        "\n",
        "        self.attention = None\n",
        "        if not use_attention:\n",
        "          shared_size=concatenated_embs_size\n",
        "\n",
        "          self.shared = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "              nn.ReLU(),\n",
        "              # nn.Dropout(0.3)\n",
        "              # nn.Linear(concatenated_embs_size, shared_size, bias=True),\n",
        "              # nn.ReLU()\n",
        "              )\n",
        "          self.prop_specific = nn.Sequential(\n",
        "              nn.Linear(shared_size*self.n_properties, self.n_properties, bias=True),\n",
        "              )\n",
        "          \n",
        "          #self.clf = nn.Linear(self.n_properties*shared_size, self.n_properties, bias=True)\n",
        "          #self.clf = nn.Linear(shared_size, self.n_properties, bias=True)\n",
        "        else: # \"shared\" not really best name here...\n",
        "          self.first_guess = nn.Sequential(\n",
        "              nn.Linear(concatenated_embs_size, self.n_properties, bias=True),\n",
        "              #\n",
        "              )\n",
        "          self.updates = nn.Sequential(\n",
        "              nn.Linear(self.n_properties, self.n_properties, bias=False),\n",
        "              nn.Tanh()\n",
        "              )\n",
        "\n",
        "\n",
        "    def forward(self, sents, sent_lens, preds, heads):\n",
        "\n",
        "        # Sort the sentences so that the LSTM can process properly\n",
        "        B, _, = sents.shape\n",
        "\n",
        "\n",
        "        if self.lstm != None:\n",
        "          lens_sorted = sent_lens\n",
        "          sents_sorted = sents\n",
        "          indices = None\n",
        "          if(len(sents) > 1):\n",
        "              lens_sorted, indices = torch.sort(lens_sorted, descending=True)\n",
        "              lens_sorted = lens_sorted.to(device)\n",
        "              indices = indices.to(device)\n",
        "              sents_sorted = sents_sorted.index_select(0, indices).to(device)\n",
        "          w_embs = self.word_emb(sents_sorted)\n",
        "          packed_lstm_input = pack_padded_sequence(\n",
        "                  w_embs, lens_sorted, batch_first=True)\n",
        "\n",
        "          lstm_outs = self.lstm(packed_lstm_input, indices)\n",
        "          pred_reps = lstm_outs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = lstm_outs[np.arange(B), heads] # same as above\n",
        "        else:\n",
        "          w_embs = self.word_emb(sents)\n",
        "          pred_reps = w_embs[np.arange(B), preds] # expecting (B, h_size)\n",
        "          head_reps = w_embs[np.arange(B), heads] # same as above\n",
        "\n",
        "        if self.direction_feature:\n",
        "          head_before_pred = torch.unsqueeze((preds > heads), -1).float() # (B,)\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps, head_before_pred], dim=-1) # (B, 2*h_size)\n",
        "        else:\n",
        "          pred_head_cat = torch.cat([pred_reps, head_reps], dim=-1) # (B, 2*h_size)\n",
        "\n",
        "        if self.attention == None:\n",
        "          x = self.shared(pred_head_cat) # (B, size_shared) # For lstm\n",
        "          logits = self.prop_specific(x.repeat(1, self.n_properties)) # Don't repeat on axis 0\n",
        "        else:\n",
        "          first_guess = self.first_guess(pred_head_cat) # (B, size_shared) # For lstm\n",
        "          #clf_input = clf_input.repeat(1, self.n_properties) # Don't repeat on axis 0\n",
        "          #updates = self.updates(first_guess) # (B, size_shared) # For lstm\n",
        "          #logits = self.clf(shared_out) # (B, properties)\n",
        "          #logits = first_guess + updates # Residual model\n",
        "          logits = first_guess # Residual model\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict(self, logits):\n",
        "        predictions = (logits.sign() + 1) / 2\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "class MyLSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "            emb_size=None,\n",
        "            h_size=None,\n",
        "            directions=None,\n",
        "            properties=None):\n",
        "        super(MyLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "                input_size=emb_size,    \n",
        "                hidden_size=h_size,\n",
        "                num_layers=1,\n",
        "                bidirectional=(directions == 2),\n",
        "                batch_first=True,\n",
        "                dropout=0.1,\n",
        "                bias=True)\n",
        "        \n",
        "        self.lstm_drop = nn.Dropout(0.)\n",
        "\n",
        "    def forward(self, packed_lstm_input, indices):\n",
        "        outputs, _ = self.lstm(packed_lstm_input)\n",
        "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "\n",
        "        # Unsort sentences to return to proper alignment with labels\n",
        "        if len(outputs) > 1:\n",
        "            outputs = unsort(outputs, indices)\n",
        "          \n",
        "        outputs = self.lstm_drop(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        " \n",
        "def unsort(batch, indices):\n",
        "    indices_inverted = torch.argsort(indices)\n",
        "    batch = batch.index_select(0, indices_inverted)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahYg0bRx-Xdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_lstm(args, model, X, y):\n",
        "    epochs = args['epochs']\n",
        "    batch_size = args['batch_size']\n",
        "    lr = args['lr']\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      if name == 'updates.0.weight':\n",
        "        original_weights = param.detach().clone()\n",
        "\n",
        "    # Data loaders\n",
        "    loader_train = data_loader(X['train'], y['train'],\n",
        "            batch_size=batch_size, shuffle_idx=True)\n",
        "    loader_dev = data_loader(X['dev'], y['dev'],\n",
        "            batch_size=batch_size, shuffle_idx=False)\n",
        "    n_train_batches = math.ceil(len(X['train']) / batch_size)\n",
        "    n_dev_batches = math.ceil(len(X['dev']) / batch_size)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = Adam(model.parameters(), lr=lr, betas=[0.9, 0.999])\n",
        "\n",
        "    # Train loop\n",
        "    training_losses = []\n",
        "    dev_losses = [4]\n",
        "    steps = 0\n",
        "    cma = 0\n",
        "    try:\n",
        "        for e in range(epochs):\n",
        "            model.train()\n",
        "            steps_ = 0\n",
        "            for b in tqdm(\n",
        "                    range(n_train_batches), \n",
        "                    ascii=True, \n",
        "                    desc=f'Epoch {e+1}/{epochs} progress',\n",
        "                    position=0,\n",
        "                    leave=True,\n",
        "                    ncols=80):\n",
        "                opt.zero_grad()\n",
        "                sents, sent_lens, preds, heads, labels = next(loader_train)\n",
        "                logits = model(sents, sent_lens, preds, heads)\n",
        "                loss = bce_loss(logits, labels)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                steps_ += 1\n",
        "                cma = (loss.item() + (steps_-1) * cma) / steps_\n",
        "                training_losses.append(cma)\n",
        "            \n",
        "            steps += steps_\n",
        "        \n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              tp = 0\n",
        "              fp = 0\n",
        "              fn = 0\n",
        "              dev_loss = 0\n",
        "              for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80, position=0, leave=True):\n",
        "                sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "                results_, metrics_, dev_loss_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "                tp += results_['tp']\n",
        "                fp += results_['fp']\n",
        "                fn += results_['fn']\n",
        "                dev_loss += dev_loss_.item()\n",
        "\n",
        "              if args['use_attention']:\n",
        "                for name, param in model.named_parameters():\n",
        "                  if name == 'updates.0.weight':\n",
        "                    updates_weights = param\n",
        "                with torch.no_grad():\n",
        "                  show_weights((updates_weights - original_weights).cpu(), properties=model.properties)\n",
        "              \n",
        "              F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "              dev_losses.append(np.mean(dev_loss))\n",
        "\n",
        "              print(f\"Epoch {e}, F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    # End of train loop\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=1)\n",
        "\n",
        "    ax[0].plot(np.arange(len(training_losses)), np.array(training_losses), color='orange')\n",
        "    ax[1].plot(np.arange(0, steps+1, n_train_batches), np.array(dev_losses), color='blue')\n",
        "    fig.show()\n",
        "\n",
        "    # Eval time!\n",
        "    # model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #   tp = 0\n",
        "    #   fp = 0\n",
        "    #   fn = 0\n",
        "    #   for b in tqdm(range(n_dev_batches), ascii=True, desc=f'Evaluating progress', ncols=80):\n",
        "    #     sents, sent_lens, preds, heads, labels = next(loader_dev)\n",
        "    #     results_, metrics_ = evaluate(args, model, sents, sent_lens, preds, heads, labels)\n",
        "    #     tp += results_['tp']\n",
        "    #     fp += results_['fp']\n",
        "    #     fn += results_['fn']\n",
        "      \n",
        "    #   F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "\n",
        "    #   print(f\"F={F*100:.2f}, p={precision*100:.2f}, r={recall*100:.2f}\")\n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "def show_weights(weights, properties=None, cmap='RdBu'):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.set_xticks(np.arange(len(properties)))\n",
        "    ax.set_yticks(np.arange(len(properties)))\n",
        "    ax.set_xticklabels(properties)\n",
        "    ax.set_yticklabels(properties)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode=\"anchor\")\n",
        "\n",
        "    plt.imshow(weights, cmap=cmap)\n",
        "    cbar = plt.colorbar()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def bce_loss(logits, labels):\n",
        "    # Expected labels : (B, num_properties)\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def data_loader(X, y, batch_size=None, shuffle_idx=False):\n",
        "    data = list(zip(X, y))\n",
        "    idx = list(range(len(data)))\n",
        "    while True:\n",
        "        if shuffle_idx:\n",
        "            random.shuffle(idx) # In-place shuffle\n",
        "        \n",
        "        for span in idx_spans(idx, batch_size):\n",
        "            batch = [data[i] for i in span]\n",
        "            yield prepare_batch(batch)\n",
        "\n",
        "\n",
        "def idx_spans(idx, span_size):\n",
        "    for i in range(0, len(idx), span_size):\n",
        "        yield idx[i:i+span_size]\n",
        "\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    # batch[i] = X, y\n",
        "    batch_size = len(batch)\n",
        "    sent_lens = torch.LongTensor([len(x[0][0]) for x in batch])\n",
        "    max_length = torch.max(sent_lens).item()\n",
        "    n_properties = len(batch[0][1])\n",
        "\n",
        "    # Zero is padding index\n",
        "    sents = torch.zeros((batch_size, max_length)).long().to(device)\n",
        "    preds = torch.zeros(batch_size).long().to(device)\n",
        "    heads = torch.zeros(batch_size).long().to(device)\n",
        "    labels = torch.zeros(batch_size, n_properties).to(device)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(batch):\n",
        "        sent, (pred_idx, head_idx) = X_batch\n",
        "        sents[i,:len(sent)] = torch.LongTensor(sent)\n",
        "        preds[i] = pred_idx\n",
        "        heads[i] = head_idx\n",
        "        labels[i] = torch.tensor(y_batch)\n",
        "\n",
        "    return sents, sent_lens, preds, heads, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyxihDMkczmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(args, model, sents, sent_lens, preds, heads, labels):\n",
        "    # Get predictions\n",
        "    logits = model(sents, sent_lens, preds, heads)\n",
        "    dev_loss = bce_loss(logits, labels)\n",
        "    predictions = model.predict(logits)\n",
        "\n",
        "    predictions, labels = predictions.cpu().numpy(), labels.cpu().numpy()\n",
        "    n_correct = (predictions == labels).astype(int).sum()\n",
        "\n",
        "    # Precision, Recall\n",
        "    eq = predictions == labels\n",
        "    neq = predictions != labels\n",
        "\n",
        "    pos_preds = predictions == 1\n",
        "    neg_preds = predictions == 0\n",
        "\n",
        "    tp = np.where(pos_preds, eq, 0).astype(int).sum()\n",
        "    fp = np.where(pos_preds, neq, 0).astype(int).sum()\n",
        "    fn = np.where(neg_preds, neq, 0).astype(int).sum()\n",
        "    \n",
        "    results = {\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'fn': fn\n",
        "            }\n",
        "\n",
        "    F, precision, recall = F_precision_recall(tp, fp, fn)\n",
        "    metrics = {'F': F, 'precision': precision, 'recall': recall}\n",
        "\n",
        "    return results, metrics, dev_loss\n",
        "\n",
        "\n",
        "def F_precision_recall(tp, fp, fn):\n",
        "    if tp + fp > 0.:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0.\n",
        "\n",
        "    if tp + fn > 0.:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0.\n",
        "\n",
        "    if precision + recall > 0.:\n",
        "        F = (2 * precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        F = 0.\n",
        "\n",
        "    return F, precision, recall\n",
        "\n",
        "\n",
        "def micro_average(results):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    for v in results.values():\n",
        "        tp += v['tp']\n",
        "        fp += v['fp']\n",
        "        fn += v['fn']\n",
        "    \n",
        "    return F_precision_recall(tp, fp, fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5YvM4uHvsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(args):\n",
        "    df = pd.read_csv(PROTO_TSV, sep='\\t')\n",
        "\n",
        "    # Sentences\n",
        "    sent_ids = set(df['Sentence.ID'].tolist())\n",
        "    sents_path = os.path.join(PICKLED_DIR, 'sents.pkl')\n",
        "    sents = None\n",
        "    with open(sents_path, 'rb') as f:\n",
        "      sents = pickle.load(f)\n",
        "\n",
        "    # Dependency data\n",
        "    # dependencies_path = os.path.join(PICKLED_DIR, 'dependencies.pkl')\n",
        "    # with open(dependencies_path, 'rb') as f:\n",
        "    #     deps, deps_just_tokens = pickle.load(f)  \n",
        "    # sents['dependencies'] = deps\n",
        "    # sents['deps_just_tokens'] = deps_just_tokens\n",
        "\n",
        "\n",
        "    # Instances\n",
        "    path = os.path.join(PICKLED_DIR, 'instances.pkl')\n",
        "    proto_instances = None\n",
        "    possible = None # Data to compare to SPRL paper\n",
        "    with open(path, 'rb') as f:\n",
        "      proto_instances, possible = pickle.load(f)\n",
        "\n",
        "    # Word embedding data\n",
        "    w2e = None\n",
        "    path = os.path.join(PICKLED_DIR, f\"glove_{args['glove_d']}.pkl\")\n",
        "    with open(path, 'rb') as f:\n",
        "      w2e = pickle.load(f)\n",
        "\n",
        "    w2i, i2w = None, None\n",
        "    emb_np = None\n",
        "    X, y = None, None\n",
        "    dicts_path = os.path.join(PICKLED_DIR, 'dicts.pkl')\n",
        "    with open(dicts_path, 'rb') as f:\n",
        "        w2i, i2w = pickle.load(f)\n",
        "    \n",
        "    emb_np_path = os.path.join(PICKLED_DIR, 'emb_np.pkl')\n",
        "    with open(emb_np_path, 'rb') as f:\n",
        "        emb_np = pickle.load(f)\n",
        "    \n",
        "    lstm_data_path = os.path.join(PICKLED_DIR, 'lstm_data.pkl')\n",
        "    with open(lstm_data_path, 'rb') as f:\n",
        "        X, y = pickle.load(f)\n",
        "\n",
        "    return {'df': df, \n",
        "            'proto_instances': proto_instances, \n",
        "            'possible': possible,\n",
        "            'sents': sents,\n",
        "            'w2e': w2e,\n",
        "            'sent_ids': sent_ids,\n",
        "            'lstm_data': (X,y),\n",
        "            'dicts': (w2i, i2w),\n",
        "            'emb_np': emb_np}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erm6Foa6jWJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def co_occurrences(y_train):\n",
        "  n_props = y_train[0].shape[0]\n",
        "  co_occur = np.zeros((n_props, n_props))\n",
        "  anti_occur = np.zeros((n_props, n_props))\n",
        "  for labels in y_train:\n",
        "    for i in range(n_props):\n",
        "      for j in range(i+1, n_props):\n",
        "        if labels[i] == 1:\n",
        "          if labels[j] == 1:\n",
        "            co_occur[i,j] += 1\n",
        "            co_occur[j,i] += 1\n",
        "          else:\n",
        "            anti_occur[i,j] += 1\n",
        "            anti_occur[j,i] += 1\n",
        "  \n",
        "\n",
        "  return co_occur, anti_occur\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUbR-mhy-dRb",
        "colab_type": "code",
        "outputId": "3ae0c7d1-f7bb-4ba3-daaf-69d04cdb7f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "args = {\n",
        "    'epochs': 10,\n",
        "    'seed': 7,\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 100,\n",
        "    'h_size': 300,\n",
        "    #'shared_size': 300,\n",
        "    'glove_d': 300,\n",
        "    'use_attention': False,\n",
        "    'use_lstm': False\n",
        "}\n",
        "\n",
        "seed = args['seed']\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "data = get_data(args)\n",
        "\n",
        "w2i, i2w = data['dicts']\n",
        "emb_np = data['emb_np']\n",
        "X, y = data['lstm_data']\n",
        "\n",
        "#co_occur, anti_occur = co_occurrences(y['train'])\n",
        "#show_weights(co_occur, properties=PROPERTIES, cmap='Greens')\n",
        "#show_weights(anti_occur, properties=PROPERTIES, cmap='Reds')\n",
        "#show_weights(co_occur - anti_occur, properties=PROPERTIES)\n",
        "\n",
        "\n",
        "model = SPRL(\n",
        "    vocab_size=len(w2i),\n",
        "    emb_size=int(args['glove_d']),\n",
        "    h_size=args['h_size'],\n",
        "    #shared_size=args['shared_size'],\n",
        "    padding_idx=w2i[PAD_TOKEN],\n",
        "    emb_np=emb_np,\n",
        "    properties=PROPERTIES,\n",
        "    use_attention=args['use_attention'],\n",
        "    use_lstm=args['use_lstm'],\n",
        "    direction_feature=False)\n",
        "model.to(device)\n",
        "\n",
        "train_lstm(args, model, X, y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 progress: 100%|######################| 78/78 [00:01<00:00, 74.56it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 85.73it/s]\n",
            "Epoch 2/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 78.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, F=75.42, p=79.81, r=71.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10 progress: 100%|######################| 78/78 [00:01<00:00, 77.82it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 89.41it/s]\n",
            "Epoch 3/10 progress:   8%|#7                     | 6/78 [00:00<00:01, 59.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, F=76.10, p=80.29, r=72.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10 progress: 100%|######################| 78/78 [00:01<00:00, 72.30it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 92.09it/s]\n",
            "Epoch 4/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 72.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, F=76.90, p=78.96, r=74.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10 progress: 100%|######################| 78/78 [00:01<00:00, 75.21it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 88.10it/s]\n",
            "Epoch 5/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 74.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, F=77.12, p=78.63, r=75.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10 progress: 100%|######################| 78/78 [00:01<00:00, 75.05it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 85.03it/s]\n",
            "Epoch 6/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 73.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, F=75.58, p=79.49, r=72.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10 progress: 100%|######################| 78/78 [00:01<00:00, 77.76it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 82.99it/s]\n",
            "Epoch 7/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 75.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, F=76.12, p=78.43, r=73.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/10 progress: 100%|######################| 78/78 [00:01<00:00, 71.08it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 68.53it/s]\n",
            "Epoch 8/10 progress:   8%|#7                     | 6/78 [00:00<00:01, 53.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, F=75.54, p=76.79, r=74.33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10 progress: 100%|######################| 78/78 [00:01<00:00, 65.37it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 83.32it/s]\n",
            "Epoch 9/10 progress:  10%|##3                    | 8/78 [00:00<00:00, 77.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, F=76.06, p=77.17, r=74.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10 progress: 100%|######################| 78/78 [00:01<00:00, 76.13it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 82.42it/s]\n",
            "Epoch 10/10 progress:  10%|##2                   | 8/78 [00:00<00:00, 78.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, F=75.99, p=77.36, r=74.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10 progress: 100%|#####################| 78/78 [00:01<00:00, 64.00it/s]\n",
            "Evaluating progress: 100%|######################| 10/10 [00:00<00:00, 87.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, F=76.19, p=77.07, r=75.34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}